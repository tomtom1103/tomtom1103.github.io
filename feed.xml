<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.3">Jekyll</generator><link href="https://tomtom1103.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://tomtom1103.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-02-28T11:53:11+00:00</updated><id>https://tomtom1103.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">The Oncology of Breast Cancer</title><link href="https://tomtom1103.github.io/blog/2022/oncology1/" rel="alternate" type="text/html" title="The Oncology of Breast Cancer"/><published>2022-09-01T00:00:00+00:00</published><updated>2022-09-01T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/oncology1</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/oncology1/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>Oncology</li> <li>Anatomy of Breast Cancer</li> <li>TNM Classification of Breast Cancer</li> <li>Biopsy of Breast Cancer</li> <li>Mucocele-like Lesions of the Breast</li> </ul> <h2 id="oncology">Oncology</h2> <blockquote> <p><strong>Oncology</strong> is a branch of medicine that deals with the prevention, diagnosis, and treatment of cancer.</p> </blockquote> <p>비전공자 입장에서 의학은 거대고 두려운 미지의 영역이다. 하지만 의학 용어는 대부분 라틴어에 어원을 두고 있기 때문에, 논문을 읽는데 있어 시간만 투자하면 이해 할 수 있다.</p> <p><strong>Oncology 의 기본 의학 용어</strong></p> <table> <thead> <tr> <th>Terminology</th> <th>해석</th> </tr> </thead> <tbody> <tr> <td>Epithelium</td> <td>상피</td> </tr> <tr> <td>Carcinoma</td> <td>장기/피부의 상피로부터 시작되는 암의 일종</td> </tr> <tr> <td>Atypical</td> <td>비정형을 띄는</td> </tr> <tr> <td>Hyperplasia</td> <td>세포의 과다증식</td> </tr> <tr> <td>Nuclear Atypia</td> <td>세포핵의 비정형성</td> </tr> <tr> <td>Histopathologic</td> <td>조직/세포의 변화에 의거</td> </tr> <tr> <td>Stroma</td> <td>버팀질</td> </tr> <tr> <td>Lesion</td> <td>병변</td> </tr> <tr> <td>Incipient</td> <td>초기</td> </tr> <tr> <td>Intralesional</td> <td>병변끼리의 연관성에 의거</td> </tr> <tr> <td>Extravasated</td> <td>혈액/점액 등이 관 외로 흘러나오는</td> </tr> <tr> <td>Hypocellular</td> <td>비정상적으로 세포의 수가 적은</td> </tr> <tr> <td>Florid</td> <td>완전히 발달한</td> </tr> <tr> <td>Invasive</td> <td>침윤성</td> </tr> <tr> <td>Stereotactical</td> <td>날카로운 도구같은</td> </tr> <tr> <td><em>In situ</em></td> <td>원위치의, 제자리에 있는</td> </tr> </tbody> </table> <p><br/></p> <p>위와 같이 어원을 이해한다면 빠른 이해를 할 수 있다. 예시로 Hyper, Hypo 는 각각 과다한, 적은 을 의미하는 접두사이며 cellular 은 세포에 관한- 정도의 의미다. 그렇다면 Hypocellular 은 비정상적으로 세포의 수가 적은 정도로 해석할 수 있다. Typical 은 전형적, 혹은 정상적인 상태이며 a- 접두사가 붙은 Atypical 은 비정형의 뜻으로 해석할 수 있다.</p> <p>의학 논문에서 많이 등장하는 단어 <em>-In situ</em> 는 암세포가 발병한 위치에만 머물고 전이되지 않은 암을 의미한다. <strong>대중들이 알고 있는 0기 암이 여기에 해당된다.</strong> 만약 상피에서 시작된 암, 즉 Carcinoma 라면, - Carcinoma <em>In situ</em> 는 상피내암을 의미한다. 그 앞에 장기의 접두사가 붙으면 정확히 무슨 암인지 알 수 있다.</p> <h2 id="anatomy-of-breast-cancer">Anatomy of Breast Cancer</h2> <p>유방암은 말 그대로 유방 조직에 암이 발생하는 것을 말한다. 현재 대한민국에서 여성 암 발병률 1위를 차지하고 있고, 매해 유방암 진단을 받는 환자는 2만명에 육박한다. 비전공자 입장에서 이해한 유방암에 대해 서술해보고자 한다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/knowledge/oncology1/img1-480.webp 480w,/assets/img/posts/knowledge/oncology1/img1-800.webp 800w,/assets/img/posts/knowledge/oncology1/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/knowledge/oncology1/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>유방 속 조직은 크게 두가지, 실질조직과 간질조직으로 나뉜다.</p> <ul> <li><strong>실질조직</strong>: 젖을 분비하는 Lobule (소엽), 젖을 유두로 운반하는 Duct (유관)</li> <li><strong>간질조직</strong>: 실질조직 사이를 지탱하는 지방, 혈관, 신경, 림프관 등등 결합조직</li> </ul> <p>성인 여성 기준으로 유두를 중심으로 약 20개의 Duct 가 방사상으로 각 Lobule 과 연결되어 있고, 각 Lobule 안엔 젖을 생성하는 Mammary Gland (유선)이 있다.</p> <p>여느 암과 마찬가지로 유방암은 유방 내 여러 조직에서 발생 할 수 있기 때문에 ‘유방암’ 이라 정의되는 암은 한두가지가 아니다. 하지만 대부분의 유방암은 실질조직 (Lobule, Duct) 에서 발생하고, 실질조직들의 상피에서 발생하기 때문에 대표적인 유방암은 <strong>Ductal Carcinoma (유관암) 과 Lobular Carcinoma (소엽암)</strong> 이다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/knowledge/oncology1/img2-480.webp 480w,/assets/img/posts/knowledge/oncology1/img2-800.webp 800w,/assets/img/posts/knowledge/oncology1/img2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/knowledge/oncology1/img2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>Ductal Carcinoma 와 Lobular Carcinoma 도 암세포의 전이의 유무로 구분 할 수 있다. 앞서 서술했듯이 <em>-In situ</em> 암이면 상피에서 발병되어 전이가 되지 않은 상태며, 만약 상피에서 외부로 암세포가 전이되었다면 이는 Invasive Carcinoma (침윤암) 이 된다.</p> <ul> <li>Ductal Carcinoma in situ (DCIS) - 유관 상피내암 - 0기암</li> <li>Lobular Carcinoma in situ (LCIS) - 소엽 상피내암 - 0기암</li> <li>Invasive Ductal Carcinoma - 침윤성 유관암 - 1기암</li> <li>Invasive Lobular Carcinoma - 침윤성 소엽암- 1기암</li> </ul> <p>유방암은 다양한 아형이 존재하지만, 진단되는 유방암의 90%는 유관암과 소엽암이다. 이중 0기암 (상피내암)은 전체 유방암의 8%, 그리고 1~2기 유방암은 약 70% 를 차지하기 때문에 완치를 기대할 수 있는 조기유방암이 전체 유방암 병기의 약 80%를 차지한다.</p> <h2 id="tnm-classification-of-breast-cancer">TNM Classification of Breast Cancer</h2> <p>일반적으로 유방암의 병기는 0~4기로 나눌 수 있다. 유방암의 병기를 나눌때 <strong>TNM 분류방식</strong> 이란걸 쓴다. 이는 Tumor (종양) 의 크기와 invasion 정도를, 주위 Node (림프절) 로 퍼진 정도를, 그리고 다른 장기나 신체조직으로의 Metastasis (전이) 에 따라 암의 병기를 분류하는 기준이다. 이 세 요소의 조합으로 암을 0~4기 암으로 분류하고, A,B, 혹은 A,B,C 로 하위분류한다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/knowledge/oncology1/img3-480.webp 480w,/assets/img/posts/knowledge/oncology1/img3-800.webp 800w,/assets/img/posts/knowledge/oncology1/img3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/knowledge/oncology1/img3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>상피내암은 암이지만 0기암으로 분류하는 이유는 다른 조직으로의 직접적인 침범이 없는 상태이기 때문이다. 그리고 유방암은 본질적으로 클론성 질환 (clonal) 이기 때문에 오랜 기간동안 비침습적인 질환, 또는 침습적이지만 전이가 안된 상태로 지속될 수 있다. 따라서 치료를 받으면 완치가 가능한 암이다. 하지만 완치가 됐더라도 재발하는 경우가 있는데, 이는 유방암을 위한 조직검사의 기술적 한계때문에 그렇다. 조직검사 중 incidental 한 침윤암을 잡아내지 못하면, 나중에 재발되거나 전이될 가능성이 희박하게나마 있다.</p> <p>2017년의 통계에 따르면 유방암의 5년 예후는 다음과 같다.</p> <ul> <li><strong>Stage 0</strong> : 99%</li> <li><strong>Stage 1</strong> : 98%</li> <li><strong>Stage 2</strong> : 93%</li> <li><strong>Stage 3</strong> : 72%</li> <li><strong>Stage 4</strong> : 22%</li> </ul> <p>0~2기를 <em>조기유방암</em> 이라 칭하는 이유는 비교적 예후가 좋기 때문이다.</p> <h2 id="biopsy-of-breast-cancer">Biopsy of Breast Cancer</h2> <p>대부분 건강검진을 할 때 진행하는 유방촬영술, 유방초음파, CT, MRI 을 통해 유방의 비정형성을 발견한다. 비정형성은 암을 의미하는 것이 아니기 때문에 보다 자세한 검진을 위해 Biopsy (조직검사) 를 한다. 조직검사로 의심되는 병변 조직에서 소량의 세포를 추출한뒤 암인지 아닌지 판단한다.</p> <blockquote> <p>Oncology 에서 최종 암 진단을 내리는 유일한 방법은 병리 조직학적인 Biopsy 뿐이다.</p> </blockquote> <p>유방암을 진단하기 위한 조직검사는 생검이라고도 부른다. 생검은 생체검사의 줄임말로, 날카로운 도구로 세포를 추출하는 과정을 의미하는데 유방의 조직검사는 대부분 이런 도구로 진행되기 때문에 유방에 있어서는 조직검사=생검 이라고 볼 수 있다.</p> <p>유방의 생검은 몇가지 종류가 있는데, 일반적으로 사용되는 생검은 다음과 같다.</p> <ol> <li>Fine Needle Aspiration Cytology (FNAC, 세침흡인세포검사)</li> <li>Fine Needle Aspiration Biopsy (FNAB, 미세침흡인생검술)</li> <li>Core Needle Biopsy (CNB, 중심침생검)</li> <li>Exisional Biopsy (절제생검)</li> <li>Incisional Biopsy (절개생검)</li> <li>Mammotome Biopsy (맘모톰 생검)</li> </ol> <p>맘모톰 생검은 맘모톰 사 에서 개발한 맘모톰 도구로 진행하는 생검을 의미하는데, 다른 생검술과 비교했을때 더 많은 양의 검체를 얻을 수 있기 때문에 대부분의 한국 병원에선 맘모톰 도구를 수입해 생검을 진행한다.</p> <h2 id="mucocele-like-lesions-of-the-breast">Mucocele-like Lesions of the Breast</h2> <p>앞서 서술했듯이 유방암은 실질조직에서의 Carcinoma 가 주류다. 이러한 유방암이 발생하는 이유는 다양하지만, 비교적 연구자료가 많지 않은 점액성 병변에 대해 조사를 했다. 점액성 병변 (Mucocele-like Lesions of the Breast) 는 1986년 Rosen 의 연구에 처음 정의되었으며, 상피내 점액을 포함한 낭종이라고 서술하였다. 이 점액성 병변은 각 Series (장기간동안 환자를 추적관찰하여 작성한 연구보고서) 마다 통계치가 상이하다. 이중 Jaffer 의 Benign mucocele-like lesions of the breast: revisited 논문에서 점액성 병변의 다양한 Series 를 분석하였다.</p> <p>해당 논문에선 61명의 점액성 병변 환자 중 50명을 관찰-추적하였다.</p> <table> <thead> <tr> <th>Case</th> <th>Count (out of 50)</th> </tr> </thead> <tbody> <tr> <td>Stereotactical diagnosis</td> <td>57/61</td> </tr> <tr> <td>Underwent excision after diagnosis</td> <td>45/50</td> </tr> <tr> <td>No residual mucocele present after excision</td> <td>37/45</td> </tr> <tr> <td>ADH present after excision</td> <td>7/45</td> </tr> <tr> <td>Residual mucocele present in ADH diagnosed patient</td> <td>3/7</td> </tr> <tr> <td>ADH and FDH present in patient</td> <td>1/7</td> </tr> <tr> <td>ADH adjacent at core biopsy site in patient</td> <td>6/7</td> </tr> <tr> <td>DCIS</td> <td>1/45</td> </tr> <tr> <td>Upstage rate (including ADH)</td> <td>17.8%</td> </tr> </tbody> </table> <p>대부분의 점액성 병변의 diagnosis 는 Stereotactical diagnosis, 즉 생검술로 진단되었다. 본 논문의 핵심은 점액성 병변의 위험성이 아니라 제거술을 진행해야 하는지를 다루고, 저자들은 그래야한다고 결론을 지었다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/knowledge/oncology1/img4-480.webp 480w,/assets/img/posts/knowledge/oncology1/img4-800.webp 800w,/assets/img/posts/knowledge/oncology1/img4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/knowledge/oncology1/img4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>이전의 Series 들은 발견된 점액성 병변의 크기, excision 후 residual molecule 의 수, calcification 등 진단과 상관관계가 있다고 하였으나, 본 논문은 이를 반박한다. <strong>즉 점액성 병변의 크기는 암의 진단의 가능성과 무관하다는 뜻이다.</strong></p> <h2 id="references">References</h2> <ul> <li><a href="https://www.nature.com/articles/modpathol2010235">Benign mucocele-like lesions of the breast: revisited</a></li> <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3268928/">Mucinous Carcinoma of the Breast in Comparison with Invasive Ductal Carcinoma: Clinicopathologic Characteristics and Prognosis</a></li> <li><a href="https://journals.lww.com/ajsp/Abstract/1996/09000/Mammary_Mucocele_like_Lesions__Benign_and.5.aspx">Mammary Mucocele-like Lesions Benign and Malignant</a></li> <li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/his.12081">Outcome of pure mucocele-like lesions diagnosed on breast core biopsy</a></li> <li><a href="https://www.sciencedirect.com/science/article/abs/pii/S0046817715004311">Mucocele-like lesions of the breast: a clinical outcome and histologic analysis of 102 cases</a></li> <li><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC5071949/">Mucocele like Tumour of the Breast Associated with Ductal Carcinoma in situ and Focal Ductal Carcinoma: What is the Best Approach to these Patients?</a></li> <li><a href="https://www.frontiersin.org/articles/10.3389/fonc.2022.855028/full">Case Report: Mucocele-Like Tumor of the Breast Associated With Ductal Carcinoma <em>In Situ</em></a></li> <li><a href="https://www.cancer.org/treatment/understanding-your-diagnosis/tests/understanding-your-pathology-report/breast-pathology/ductal-carcinoma-in-situ.html">Understanding Your Pathology Report: Ductal Carcinoma In Situ (DCIS)</a></li> <li><a href="https://breast-cancer-research.biomedcentral.com/articles/10.1186/s13058-018-0967-1">Atypical ductal hyperplasia: update on diagnosis, management, and molecular landscape</a></li> <li><a href="https://www.cancer.org/cancer/breast-cancer/about/types-of-breast-cancer/invasive-breast-cancer.html">Invasive Breast Cancer (IDC/ILC)</a></li> </ul>]]></content><author><name></name></author><category term="knowledge"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">The Internet Protocol (IPv4)</title><link href="https://tomtom1103.github.io/blog/2022/ipv4/" rel="alternate" type="text/html" title="The Internet Protocol (IPv4)"/><published>2022-08-22T00:00:00+00:00</published><updated>2022-08-22T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/ipv4</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/ipv4/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>The Internet Protocol</li> <li>Subnet Masks, Default Gateways, and Broadcast Addresses</li> <li>Public IP</li> <li>Private IP</li> </ul> <h2 id="the-internet-protocol">The Internet Protocol</h2> <p>컴퓨터를 처음 만지기 시작한 나이부터 IP 주소의 존재는 알고 있었지만, 딱히 무슨 원리로 동작하는지에 대해선 관심이 없었다. 그저 인터넷만 잘 연결되면 살아가는데 있어 별 문제가 없었기 때문이다. 하지만 최근 이사를 오며 본격적으로 홈네트워크를 구축하기 위해서 공부를 하다보니 정말 네트워킹에 대한 지식이 전무하다는 것을 깨닫고 차근차근 공부를 시작했다. IP의 작동원리는 개인 GPU 서버의 운영과 (아직 계획은 없지만) 나스 설치 등 많은 네트워킹 시스템의 근간이 되기 때문에 알아두는것이 좋다고 판단했다.</p> <p>Internet Protocol, 줄여서 IP 는 기계들의 통신을 담당하고, 다른 기계와 통신을 하고 싶은 기계는 IP주소가 필요하다. 많은 설명을 읽어봐도 제일 피부에 와닿는 설명은 <strong>전화번호</strong>다. 전화번호가 있어야만 다른 핸드폰으로 전화를 걸 수 있는 것 처럼, 컴퓨터는 IP주소가 있어야 인터넷에 접속할 수 있고 다른 컴퓨터와 통신을 할 수 있다. 윈도우머신의 터미널에 ipconfig 을 치면 간단하게 그 컴퓨터의 IP주소를 확인 할 수 있다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/devops/ipv4/img1-480.webp 480w,/assets/img/posts/devops/ipv4/img1-800.webp 800w,/assets/img/posts/devops/ipv4/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/devops/ipv4/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>IPv4 Address가 바로 컴퓨터의 IP주소다. IP주소를 처음 보면 그저 숫자의 나열로밖에 보이지 않지만, 자세히 살펴보면 1~3개의 수 뒤에 점(.)이 있고, 총 4개의 숫자와 3개의 점으로 구성되어 있다. (적어도 IPv4에선) 이 규칙은 변하지 않는다. 이 IP 주소로 컴퓨터는 인터넷에 접속할 수 있고, 다른 컴퓨터가 이 IP 주소를 통해 나와 통신을 할 수 있다.</p> <p>IP주소의 모양이 4개의 숫자와 3개의 점의 규칙을 따르는 이유가 있다. 각 숫자는 0부터 255까지의 값을 가질 수 있는데, 이는 2의 8제곱에 해당되는 수다. 그리고 IP주소엔 총 4개의 숫자가 있으므로 IP주소가 가질 수 있는 값은 총 2의 32제곱 (약 43억)이 된다. 점(.) 으로 분리된 3자리 수는 octet 이라 한다.</p> <h2 id="subnet-masks-default-gateways-and-broadcast-addresses">Subnet Masks, Default Gateways, and Broadcast Addresses</h2> <p>위의 이미지를 보면, IP주소 밑에 Subnet Mask과 Default Gateway 라는 값들도 출력이 된다. Subnet Mask 는 쉽게 말하자면 IP주소의 <strong>유동성</strong> 을 관리해주는 값이다. 내 윈도우머신의 Subnet Mask 는 255.255.255.0 이란 값을 갖고, Subnet Mask 의 octet 중 255가 있으면 이는 내 IP주소의 해당 octet 이 <strong>변하지 않고 고정된다</strong>를 의미한다.</p> <table> <thead> <tr> <th>IP Octet</th> <th>Subnet Mask Octet</th> <th>Description</th> </tr> </thead> <tbody> <tr> <td>121</td> <td>255</td> <td>고정</td> </tr> <tr> <td>138</td> <td>255</td> <td>고정</td> </tr> <tr> <td>27</td> <td>255</td> <td>고정</td> </tr> <tr> <td>66</td> <td>0</td> <td>유동적</td> </tr> </tbody> </table> <p>즉, 내 윈도우머신의 IP주소의 앞 3개의 octet 은 변하지 않지만, 접속할때 마다 마지막 octet 은 변할 수 있다. 이 Subnet Mask 가 의미하는 것은 사실 해당 네트워크의 주소다. 네트워크는 간단하게 말해서 외부로 나가지 않고 내부에서 서로 통신할 수 있는 주소를 의미하는데, 만약 내 맥북이 121.138.27.xxx 라는 IP주소를 가지고 있다면 윈도우 컴퓨터와 내부망에서 통신을 할 수 있다.</p> <p>Default Gateway 는 우리가 집에 하나씩 가지고 있는 공유기의 주소다. 공유기도 사실 기기이기 때문에 IP주소를 할당받는데, 보통 마지막 octet 의 값이 254다. 255.255.255.0의 Subnet Mask를 가지고 있는 하나의 네트워크를 예시로 들어보자. 앞 3개의 octet 은 고정이기 때문에 결국 해당 네트워크에 연결할 수 있는 호스트 (기기)의 수는 253개이다. 0부터 255까지 비어있으니 256개가 아닌 이유는, 할당 할 수 없는 3개의 default 주소가 있기 때문이다. 이 주소들은 앞서 살펴본 Default gateway, xxx.xxx.xxx.0 의 값을 갖는 network address, 그리고 xxx.xxx.xxx.255 의 값을 갖는 broadcast address 이다. 이번 장에선 설명하지 않겠지만, 간단히 생각해서 첫 호스트 주소, 마지막 호스트 주소, 그리고 공유기의 주소 빼고 하나의 네트워크에 253개의 호스트가 연결 할 수 있다.</p> <h2 id="public-ip">Public IP</h2> <p>IP주소의 표기방식을 보면 2의 32제곱의 경우의 수를 갖기 때문에 약 43억개의 고유 IP주소가 생성된다. 그리고 이 IP주소는 처음 설계되었을때 5개의 클라스로 분류되었다.</p> <table> <thead> <tr> <th>Class</th> <th>Range</th> <th>Subnet Mask</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>1.0.0.0 ~ 126.255.255.255</td> <td>255.0.0.0</td> </tr> <tr> <td>B</td> <td>128.0.0.0 ~ 191.255.0.0</td> <td>255.255.0.0</td> </tr> <tr> <td>C</td> <td>192.0.0.0 ~ 223.255.255.0</td> <td>255.255.255.0</td> </tr> <tr> <td>D</td> <td>224.0.0.0 ~ 239.255.255.255</td> <td> </td> </tr> <tr> <td>E</td> <td>240.0.0.0 ~ 255.255.255.255</td> <td> </td> </tr> </tbody> </table> <p>Class A, B, C 는 각자 다른 Subnet Mask 를 갖는다. 이 Subnet Mask 를 보면 해당 Class 의 IP주소의 capacity 를 어림짐작 할 수 있다. Class A 는 첫번째 octet 만 고정이기 때문에 126개의 네트워크밖에 없지만, 각 네트워크엔 2의 24제곱 (약 1천 6백만)개 의 호스트가 연결 할 수 있다. 반면에 Class C 는 약 1천 6백만개의 네트워크가 있으며, 각 네트워크엔 256개의 호스트만 연결 할 수 있다. Class 위로 올라갈 수록 <strong>네트워크의 수는 많아지며, 각 네트워크에 연결할 수 있는 호스트는 적어진다를 의미한다.</strong></p> <p>이렇게 Class 로 IP 를 할당하는 방식의 문제는 무엇일까? IANA (Internet Assigned Numbers Authority) 가 처음 IP주소를 관리하기 시작했을 때 Class A 네트워크를 대기업에게 무분별하게 나눠줬다. 예시로 9.0.0.0는 IBM이 독점적으로 소유하고 있으며, 이론상 IBM에게 할당된 IP주소의 수는 1천6백억개다. 처음 IP주소를 나누기 시작했을 때 절대 부족하지 않을거라 생각을 했지만, 이미 2015년엔 IP 주소가 고갈되었다. 심지어 Class D, E 는 각자 특수한 케이스로 사용되기 때문에 일반 사용자는 접근조차 못한다. 이런 상황을 타계하기 위해 등장한 것이 바로 Private IP와 Subnetting 이다.</p> <h2 id="private-ip">Private IP</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/devops/ipv4/img1-480.webp 480w,/assets/img/posts/devops/ipv4/img1-800.webp 800w,/assets/img/posts/devops/ipv4/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/devops/ipv4/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>위 사진은 나의 실제 IP주소이다. 하지만 공개해도 위험하지 않는 이유는 바로 사설 IP 주소이기 때문이다. 앞서 말한 것 처럼 공인 IP가 고갈되었기 때문에, 고갈되기 전 IANA가 몇개의 주소를 사설 IP 로 사용하도록 떼어냈다.</p> <table> <thead> <tr> <th>Class</th> <th>Range</th> <th>Subnet Mask</th> </tr> </thead> <tbody> <tr> <td>A</td> <td>10.0.0.0 ~ 10.255.255.255</td> <td>255.0.0.0</td> </tr> <tr> <td>B</td> <td>172.16.0.0 ~ 172.31.255.255</td> <td>255.255.0.0</td> </tr> <tr> <td>C</td> <td>192.168.0.0 ~ 192.168.255.255</td> <td>255.255.255.0</td> </tr> </tbody> </table> <p>위 표는 사설 IP 주소들이다. 사설 IP 는 공인 IP 와 다르게 중복해서 사용할 수 있지만, 직접 인터넷과 연결 할 수 없다. 공유기가 NAT (Network Address Translation) 이란 작업을 수행해야만 사설 IP 를 가진 호스트들이 인터넷과 통신을 할 수 있다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/devops/ipv4/img2-480.webp 480w,/assets/img/posts/devops/ipv4/img2-800.webp 800w,/assets/img/posts/devops/ipv4/img2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/devops/ipv4/img2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>기본적으로 ISP (Internet Service Provider, KT 같은 통신사) 가 공유기로 공인 IP를 할당한다. 그리고 공유기의 네트워크에 연결되어 있는 호스트들에게 사설 IP를 부여한다. 공유기의 네트워크에 연결되어 있기 때문에 IP주소 앞 3개의 octet 이 같다. 만약 윈도우머신이 인터넷으로 접속하고 싶다면, 공유기는 윈도우의 사설 IP 를 NAT 라는 작업을 통해 ISP 가 제공해준 공인 IP 로 바꿔준다 (request). 인터넷에서 response 를 받는다면 공유기가 이걸 호스트에게 전달해주는 방식이다.</p> <p>사설 IP의 등장으로 주소고갈 문제는 어느정도 해결을 할 수 있었지만, 근본적인 해결책은 아니기에 subnetting 과 IPv6 의 도입을 반길 수밖에 없다.</p>]]></content><author><name></name></author><category term="knowledge"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Bias-Variance Decomposition</title><link href="https://tomtom1103.github.io/blog/2022/biasvariance/" rel="alternate" type="text/html" title="Bias-Variance Decomposition"/><published>2022-08-20T00:00:00+00:00</published><updated>2022-08-20T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/biasvariance</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/biasvariance/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>Introduction</li> <li>Mathematical Definition</li> <li>Decomposition of Expected Test Error</li> </ul> <blockquote> <p>해당 포스트는 <a href="https://www.youtube.com/watch?v=zUJbRO0Wavo&amp;ab_channel=KilianWeinberger">Cornell CS4780 SP17</a> Killian Weinberger 교수님의 강의를 참고하였습니다.</p> </blockquote> <h2 id="introduction">Introduction</h2> <p>Bias-Variance Decomposition 은 모델의 일반화 성능을 높히기 위한 정규화 방법론들과 앙상블 방법론들의 이론적 배경이다. 실제 데이터로 학습되는 모든 모델은 어느정도의 Bias-Variance tradeoff 가 존재하기 때문에, 머신러닝을 공부 할 때 확실히 이해하고 넘어가야 하는 부분이다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/biasvariance/img1-480.webp 480w,/assets/img/posts/machinelearning/biasvariance/img1-800.webp 800w,/assets/img/posts/machinelearning/biasvariance/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/biasvariance/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p><strong>Error Due to Bias:</strong> 모델의 Expected prediction 과 실제 값의 차이다. 모델의 Expected prediction 이란 말이 생소하지만, 같은 분포에서 나온 많은 데이터셋을 통해 많은 모델을 학습시켰을 때 해당 모델들의 평균 예측치다.</p> <p><strong>Error Due to Variance:</strong> 같은 분포에서 나온 많은 데이터셋을 통해 모델을 학습시켰을 때, 한 데이터포인트에 대한 전체 평균 예측치와 개별 모델의 예측치의 차이를 의미한다. 즉, 전체 모델들간의 예측치의 차이로 해석할 수 있다.</p> <p>조금 더 쉽게 풀자면, <strong>Bias 는 모델들의 전반적인 성능이 좋은지 나쁜지를 의미하고, Variance 는 각 모델들이 서로와 얼마나 다른지를 의미한다.</strong> 머신러닝의 대부분의 모델은 둘중 하나가 높다는 특징을 가지고 있기 때문에 Bias-Variance Tradeoff 라고 불린다.</p> <p>특정 모델을 학습시켰을 때 test error 는 필연적으로 등장한다. Bias-Variance Decomposition 은 해당 error 가 Bias 에서 온 error 인지, variance 에서 온 error 인지, noise 에서 온 error 인지 평가해 줄 수 있다.</p> <h2 id="mathematical-definition">Mathematical Definition</h2> <p>\(P(X,Y)\) 라는 분포에서 i.i.d 로 데이터셋 \(D = \{(\mathbf{x}_1, y_1), \dots, (\mathbf{x}_n,y_n)\}\) 를 추출했다고 가정하자. Regression 모델을 가정했을 때, 모든 벡터 \(\mathbf{x_n}\) 에 대한 정답 라벨 \(y_n\) 은 unique 하지 않고, 분포에 따라 주어진다.</p> <blockquote> <p>영상에서 이 부분에 대해 갸우뚱하는 학생들을 위해 교수님이 직접 예시를 들어준다. 집에 대한 가격을 나타내는 데이터셋에 대해, 설명변수의 값이 모두 동일한 두개의 집은 무조건적으로 가격이 같지 않다.</p> </blockquote> <p><strong>Expected Label:</strong></p> \[\bar{y}(\mathbf{x}) = E_{y \vert \mathbf{x}} \left[Y\right] = \int\limits_y y \, \Pr(y \vert \mathbf{x}) \partial y\] <p>i.i.d 로 추출한 수많은 데이터셋들에 대해 모델을 학습시킨 뒤, 새로운 샘플 \(\mathbf{x}\) 에 대한 expected label 은 위와 같이 계산할 수 있다. 데이터셋 자체를 \(P(X,Y)\) 라는 분포에서 i.i.d 추출했기 때문에 random variable 로 취급할 수 있으므로, continuous r.v. 의 Expectation 을 구하는 것과 동일하게 \(y\) 값과 모델의 예측치들에 대해 \(y\) 로 미분해주면 된다.</p> <p><strong>Expected Test Error (given \(h_D\)):</strong></p> \[E_{(\mathbf{x},y) \sim P} \left[ \left(h_D (\mathbf{x}) - y \right)^2 \right] = \int\limits_x \! \! \int\limits_y \left( h_D(\mathbf{x}) - y\right)^2 \Pr(\mathbf{x},y) \partial y \partial \mathbf{x}.\] <p>\(D\) 라는 학습 데이터를 통해 알고리즘 \(\mathcal{A}\) 를 학습시켰다고 가정하자 (\(h_D = \mathcal{A}(D)\)). 그렇다면 해당 모델 \(h_D\) 의 Expected Test Error 은 (예시가 regression 이기 때문에 squared loss 사용) 위와 같이 구할 수 있다. \(D\) 는 앞서 설명했듯이 random variable 로 취급할 수 있고, \(h_D\) 는 \(D\) 에 대한 function 이기 때문에 마찬가지로 random variable 이다.</p> <p><strong>Expected Classifier (given \(\mathcal{A}\)):</strong></p> \[\bar{h} = E_{D \sim P^n} \left[ h_D \right] = \int\limits_D h_D \Pr(D) \partial D\] <p><strong>\(h_D\) 와 \(\mathcal{A}\) 를 구분짓는게 핵심이다.</strong> \(h_D\) 는 하나의 모델이고 \(\mathcal{A}\) 는 학습될 수 있는 모든 모델이다. 그렇기 때문에 위와 같이 expected classifer 은 분포 \(P\) 에서 추출된 \(D\) 로 학습된 모든 모델의 expectation 이라고 할 수 있다.</p> <p><strong>Expected Test Error (given \(\mathcal{A}\)):</strong></p> \[\begin{equation*} E_{\substack{(\mathbf{x},y) \sim P\\ D \sim P^n}} \left[\left(h_{D}(\mathbf{x}) - y\right)^{2}\right] = \int_{D} \int_{\mathbf{x}} \int_{y} \left( h_{D}(\mathbf{x}) - y\right)^{2} \mathrm{P}(\mathbf{x},y) \mathrm{P}(D) \partial \mathbf{x} \partial y \partial D \end{equation*}\] <p>모든 모델에 대한 expectation 을 구했기 때문에 이제 <strong>가능한 모든 모델에 대한 expected error 을 표현 할 수 있다.</strong> 우리의 목적은 \(P(X,Y)\) 에서 추출된 \(D\) 로 학습된 모델 \(\mathcal{A}\) 의 expected 성능을 구하는 것이기 때문에, 위 식이 이를 나타낸다. 이때 해당 식을 decompose 하면 정확히 어떻게 모델의 에러가 구성되어있는지 볼 수 있다.</p> <h2 id="decomposition-of-expected-test-error-given-mathcala">Decomposition of Expected Test Error (given \(\mathcal{A}\))</h2> \[E_{\mathbf{x},y,D}\left[\left[h_{D}(\mathbf{x}) - y\right]^{2}\right] \\ \\ = E_{\mathbf{x},y,D}\left[\left[\left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right) + \left(\bar{h}(\mathbf{x}) - y\right)\right]^{2}\right] \\\\ = E_{\mathbf{x}, D}\left[(\bar{h}_{D}(\mathbf{x}) - \bar{h}(\mathbf{x}))^{2}\right] \\ +2 \mathrm{\;} E_{\mathbf{x}, y, D} \left[\left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right)\left(\bar{h}(\mathbf{x}) - y\right)\right] \\ +E_{\mathbf{x}, y} \left[\left(\bar{h}(\mathbf{x}) - y\right)^{2}\right]\] <p>첫 식은 위에서 구한 Expected Test Error 이다. 이때 expectation 안에 모델의 label 의 expectation \(\bar{h}(\mathbf{x})\) 를 한번씩 빼주고 더해준다. 이를 binomial expansion 을 통해 마지막 식처럼 표현 할 수 있다. 복잡해 보이지만 결국 \((a+b)^2 = a^2+2ab+b^2\) 의 꼴이다. 이때 식의 \(2ab\) 부분은 0이 된다.</p> \[E_{\mathbf{x}, y, D} \left[ \left( h_{D}(\mathbf{x}) - y \right)^{2} \right] = \underbrace{E_{\mathbf{x}, D} \left[ \left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x}) \right)^{2} \right]}_\mathrm{Variance} + E_{\mathbf{x}, y}\left[ \left( \bar{h}(\mathbf{x}) - y \right)^{2} \right]\] <p>Variance 의 정의 자체가 해당 객체가 평균에서 얼마나 분산되어있는지 이기 때문에, 식의 첫번째 부분을 Variance 라고 할 수 있다. 식의 두번째 부분은 처음에 진행 한 것 처럼 binomial expansion 꼴로 표현하면 아래와 같아진다.</p> \[E_{\mathbf{x}, y} \left[ \left(\bar{h}(\mathbf{x}) - y \right)^{2}\right] = E_{\mathbf{x}, y} \left[ \left(\bar{h}(\mathbf{x}) -\bar y(\mathbf{x}) )+(\bar y(\mathbf{x}) - y \right)^{2}\right] \\\\ =\underbrace{E_{\mathbf{x}, y} \left[\left(\bar{y}(\mathbf{x}) - y\right)^{2}\right]}_\mathrm{Noise} + \underbrace{E_{\mathbf{x}} \left[\left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)^{2}\right]}_\mathrm{Bias^2} \\ + 2 \mathrm{\;} E_{\mathbf{x}, y} \left[ \left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)\left(\bar{y}(\mathbf{x}) - y\right)\right] \label{eq:eq3}\] <p>동일하게 \(2ab\) 부분은 사라지기 때문에, 최종적으로 expected test error 의 decomposition 은 다음과 같아진다:</p> \[\underbrace{E_{\mathbf{x}, y, D} \left[\left(h_{D}(\mathbf{x}) - y\right)^{2}\right]}_\mathrm{Expected\;Test\;Error} \\ = \underbrace{E_{\mathbf{x}, D}\left[\left(h_{D}(\mathbf{x}) - \bar{h}(\mathbf{x})\right)^{2}\right]}_\mathrm{Variance} + \underbrace{E_{\mathbf{x}, y}\left[\left(\bar{y}(\mathbf{x}) - y\right)^{2}\right]}_\mathrm{Noise} + \underbrace{E_{\mathbf{x}}\left[\left(\bar{h}(\mathbf{x}) - \bar{y}(\mathbf{x})\right)^{2}\right]}_\mathrm{Bias^2}\] <p><strong>즉, Bias-Variance decomposition 은 한 머신러닝 알고리즘의 expected test error (혹은 성능) 은 3개의 요인으로 나누어 설명할 수 있음을 의미한다. 한개의 모델이 다른 모델들과 얼마나 다른지를 설명하는 Variance, 전체 모델들의 평균 예측치와 실제값들의 평균의 차를 나타내는 Bias (평균 성능이라고 봐도 무방하다), 그리고 설명할 수 없는 data intrinsic 한 noise 의 합으로 하나의 모델의 성능을 나타낼 수 있다.</strong></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/biasvariance/img2-480.webp 480w,/assets/img/posts/machinelearning/biasvariance/img2-800.webp 800w,/assets/img/posts/machinelearning/biasvariance/img2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/biasvariance/img2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>이상적인 알고리즘은 Bias 와 Variance 가 낮지만, 현실적으로 tradeoff 가 발생하기 때문에 필연적으로 둘중 하나는 크다. 보통 Model Compexity 가 낮은 알고리즘들 (ex. LogReg, LDA) 는 High Bias Low Variance 이며, Model Complexity 가 높은 알고리즘들 (ex. NN, Full DT, SVM) 은 Low Bias High Variance 이다.</p> <p>우측 하단의 그림을 보면 Model complexity 가 높을수록 높은 Variance 를 가졌다는 의미가 와닿는다. Training sample 에 대한 에러율은 0에 수렴하지만, 같은 분포에서 추출한 또다른 데이터셋인 testing sample 에 대한 에러는 굉장히 높다. 이는 데이터셋의 작은 변화에도 모델이 민감하게 반응한다는 것을 의미하며, 자주 접하는 과적합이 해당 모델들의 고질적인 문제를 표현한다.</p> <blockquote> <p>Low Bias High Variance 를 가진 High complexity 모델들은 과적합에 취약하다는 것은 Bias-Variance Decomposition 에서 수학적으로 증명된 것이다. 그렇기 때문에 Overfitting 에 대한 연구들은 전부 High Variance 를 가진 딥러닝 알고리즘들을 예시로 든다.</p> </blockquote>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Markov Chain Monte Carlo Algorithm</title><link href="https://tomtom1103.github.io/blog/2022/mcmc/" rel="alternate" type="text/html" title="Markov Chain Monte Carlo Algorithm"/><published>2022-08-17T00:00:00+00:00</published><updated>2022-08-17T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/mcmc</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/mcmc/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li> <p>Bayesian Inference - Frequentism vs. Bayesianism</p> </li> <li> <p>Likelihood and Maximum Likelihood Estimation</p> </li> <li> <p>Rejection Sampling</p> <ul> <li>Proposal Distribution \(g(x)\)</li> </ul> </li> <li> <p>Markov Chain Monte Carlo</p> <ul> <li> <p>MCMC: Metropolis Algorithm (Sampling)</p> </li> <li> <p>Pseudocode</p> </li> <li> <p>MCMC: Bayesian Estimation</p> </li> </ul> </li> </ul> <h2 id="bayesian-inference---frequentism-vs-bayesianism">Bayesian Inference - Frequentism vs. Bayesianism</h2> <p>통계를 처음 공부하면 베이즈 추론이란 것은 그냥 계산식에 때려넣고 확률을 계산하는 식으로 배우지만, 역사적으로 보면 확률에 대한 새로운 paradigm 을 제시한 수학자의 유산이다. 우리가 익숙한 ‘통계’ 에선 동전을 던졌을 때 뒷면이 나올 확률은 0.5 라고 배운다. 하지만 토마스 베이즈가 정의한 베이지안 추론에선 확률을 완전히 새로운 관점에서 접근하며, 동전의 뒷면이 나올 확률을 0.5 라고 해석하지 않고 동전을 던졌을 시 ‘뒷면이 나왔다는 주장의 신뢰도가 0.5다’ 라고 해석한다.</p> <p><strong>전자가 Frequentism (빈도주의)며 후자가 Bayesianism (베이지안주의) 다.</strong></p> <p>빈도주의에선 어떠한 태스크를 무한히 수행했을 때 확률이 특정 값으로 수렴하며, 우린 이걸 해석하기 쉽게 ‘확률’ 이라고 부르지만, 베이지안주의에선 확률을 <strong>주장에 대한 신뢰도</strong> 로 해석하는 새로운 관점을 제시한다.</p> <p><strong>Bayesianism</strong> 은 베이즈가 베이즈 정리를 발표하면서 처음 나오게 된 통계를 재해석하는 관점이다.</p> \[P(H|E) = \frac{P(E \mid H)P(H)}{P(E)}\] <p>위 공식은 공학도에겐 익숙한 베이즈 정리의 공식이다. 베이즈 정리는 사전확률과 사후확률로 나뉘는데,</p> <ul> <li> <p>사전확률 (Hypothesis) = \(P(H)\)</p> </li> <li> <p>사후확률 (Hypothesis given Evidence) = \(P(H \mid E)\)</p> </li> <li> <p>우도 (Likelihood, Evidence given Hypothesis) = \(P(E \mid H)\)</p> </li> <li> <p>새로운 정보의 신뢰도 (Evidence)= \(P(E)\)</p> </li> </ul> <p>이다. 베이즈 정리가 말하는 것은 가설 (\(Hypothesis\)), 혹은 <strong>어떤 사건이 발생했다는 주장</strong>이 있으면 새로운 증거(\(Evidence\)) 를 통해 이 가설의 <strong>신뢰도</strong> 를 갱신해 내가는 과정이다.</p> <blockquote> <p>Example: 이종현은 똑똑하다 라는 Statement 가 있다고 생각하자. 이 Statment 는 가설이 되며, 이 가설은 아무런 증거가 없으면 가설의 신뢰도는 처음 Statement 를 주장했을 때와 동일하다. 하지만 새로운 증거 (ex. 전공 평균평점이 4.3이다 <del>택도없다</del>) 가 제시되면, 이 증거를 통해 ‘이종현은 똑똑하다’ 라는 가설의 신뢰도를 갱신해 나갈 수 있다.</p> </blockquote> <p><strong>베이즈 정리는 결국 추가적인 근거를 확보해 진리로 더 다가갈 수 있는 철학을 수학적으로 풀어낸 것이다.</strong></p> <h2 id="likelihood-and-maximum-likelihood-estimation">Likelihood and Maximum Likelihood Estimation</h2> <p>MLE (Maximum Likelihood Estimation) 을 설명하기 전 다수가 헷갈려하는 통계적 단어를 짚고 넘어가보자. 모집단 (\(Population\)) 은 전체 집단이고, 모수(\(Parameter\)) 는 모집단을 통계적으로 표현하는 수치들 (모평균, 모분산 등등) 이다.</p> <table> <thead> <tr> <th>명칭</th> <th>설명</th> </tr> </thead> <tbody> <tr> <td>모집단 (Population)</td> <td>특성의 전체 집단</td> </tr> <tr> <td>모수 (Parameter)</td> <td>모집단을 통계적으로 표현해주는 수치</td> </tr> <tr> <td>표본집단 (Sample)</td> <td>모집단에서 추출한 값들의 집합</td> </tr> <tr> <td>통계치 (Statistics)</td> <td>표본집단을 통계적으로 표현해주는 수치</td> </tr> </tbody> </table> <p>표본집단 (\(Sample\))은 모집단에서 랜덤하게 추출한 값들의 집합이다. 모수가 모집단을 통계적으로 표현한 수치면 표본집단은 <strong>통계치</strong>를 통해 표본집단을 표현한다.</p> <p>실제 세상에선 모집단에 대한 모수를 알 수 없기 때문에, 모집단에서 표본집단을 추출 한 후 통계치를 통해 모집단에 대한 정보를 <strong>추정</strong>할 수 밖에 없다. 모집단에 대한 진리를 알기 위해 먼저 샘플링, 즉 표본집단을 추출하는 과정도 거쳐야 하고, 이 표본집단을 통해 모집단의 모수를 추정해야 한다.</p> <ul> <li> <p>\(Sampling\) = 모집단 (\(Population\)) 에서 표본집단 (\(Sample\)) 을 추출하는 과정</p> </li> <li> <p>\(Parameter Estimation\) = 표본집단 (\(Sample\)) 을 통해 모집단 (\(Population\)) 의 모수 (\(Parameter\)) 을 추정하는 과정</p> </li> </ul> <p>통계학의 궁극적 목표는 모집단에 대한 완벽한 정보를 구축하는 것이지만, 앞서 언급한 것 처럼 사실상 불가능하다. 그렇기 때문에 일련의 과정을 걸쳐 모집단에 대한 지례짐작만 할 수 있는데, 얼마나 <strong>잘</strong> 지례짐작 하느냐가 관건이다. 그렇기 때문에 Sampling 과 Parameter Estimation 은 어떻게 하냐에 따라 결과가 상이 할 수 있는데, 최대우도법 (Maximum Likelihood Estimation) 은 Parameter Estimation 방법론 중 하나다. 최대우도법은 베이즈 정리의 Likelihood 라는 것을 이용하는데, 수식적으로 \(P(E \mid H)\) 로 정의된다.</p> <blockquote> <p>모집단에 대한 정보를 알기 위해 샘플링을 하고 파라미터를 추정한다.</p> <p>파라미터를 잘 추정할 수 있다면 결국 그 모집단의 분포를 알게 되는것 - 통계적으로 유의미!</p> </blockquote> <p>최대우도법은 베이즈 정리에서부터 파생된 것이기 때문에, 베이즈 정리의 우도공식인 \(P(E \mid H)\) 보다 \(P(D \mid {\theta})\) (Data given Parameter) 로 더 많이 표현한다. 베이지안 추론의 관점에서 포현하면, <strong>데이터포인트가 이 파라미터에서 나왔다는 주장의 신뢰도</strong>다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/mcmc/one-480.webp 480w,/assets/img/posts/machinelearning/mcmc/one-800.webp 800w,/assets/img/posts/machinelearning/mcmc/one-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/mcmc/one.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <blockquote> <p>Sidenote: 여러 소스를 참고했는데, 사람들이 대부분 헷갈려하는 Likelihood, Likelihood Function, Total Likelihood 가 다 같은 말이다.</p> </blockquote> <p>최대우도법을 예시로 설명해보겠다. 위의 모집단에서 샘플링한 4개의 데이터포인트가 있다. 이 데이터포인트들이 두개의 분포 중 어떤 모집단 분포에서 나왔을 가능성이 높은가를 정량적으로 계산하는 것이 Likelihood 이다. Likelihood 를 계산하려면 먼저 각 데이터포인트에 대한 Likelihood 기여도를 \(P(x \mid \theta)\) 로 계산해야 한다.</p> <p>모든 데이터포인트에 대한 Likelihood 기여도를 계산하고 곱해준 값이 바로 Likelihood (혹은 Total Likelihood, 혹은 Value of the Likelihood Function) 이 된다. 그리고 계산을 더 편하게 하기 위해 로그값을 취해 Log Likelihood 값으로 표현한다.</p> <p><strong>특정 데이터포인트에 대해 후보 파라미터를 주면, 이때 Likelihood 값이 제일 큰 파라미터를 선택해서 이 데이터포인트들이 이 파라미터를 갖는 모집단에서 나왔다고 가정하는 것이 최대우도법이다.</strong></p> <p><strong><em>이때 파라미터를 추정한다 → 확률밀도함수를 추정한다 라는 것을 알 수 있다.</em></strong></p> <blockquote> <p>MLE: Parameter \(\theta\) 로 구성된 \((\theta_1, ... ,\theta_m)\) 어떤 확률밀도함수 \(P(x \mid \theta)\) 에서 관측된 표본 데이터집합을 \(x (x_1, ... , x_n)\) 라고 했을 때, 이 표본들로부터 Parameter \(\theta\) 를 추정하는 방법.</p> </blockquote> <table> <thead> <tr> <th>Values</th> <th>Functions</th> </tr> </thead> <tbody> <tr> <td>Likelihood</td> <td>\(P(D|\theta)\ or \ P(x|\theta)\)</td> </tr> <tr> <td>Likelihood 기여도</td> <td>\(P(x_k|\theta)\)</td> </tr> <tr> <td>Likelihood Function</td> <td>\(P(x|\theta) = \prod P(x_k|\theta)\)</td> </tr> <tr> <td>Log-Likelihood Function</td> <td>\(L(\theta|x) = \sum logP(x_k|\theta)\)</td> </tr> <tr> <td>Maximum Likelihood Estimation</td> <td>\(argmax \ L(\theta|x)\)</td> </tr> </tbody> </table> <h2 id="rejection-sampling">Rejection Sampling</h2> <p>최대우도법이 파라미터 추정방법이였다면 기각샘플링 (Rejection Sampling)은 말 그대로 샘플링 방법이다. 샘플링은 간단하게 보면 모집단에서 표본을 추출하는 것이지만, 모집단의 분포를 모르기 때문에 실제 모집단의 분포와 비슷하게 샘플링을 하는 것은 어렵다.</p> <p>수학적인 관점에서 샘플링을 보면 cdf 의 역함수 연산을 하는 것인데, 이 프로세스 자체가 어려울 뿐만 아니라 애초에 확률밀도함수에 대해 적분연산을 취해줘야 cdf 를 구할 수 있기 때문에 수치적으로 정확하지도 않다.</p> <p><strong>즉, 설령 모집단의 확률밀도함수를 알고 있다고 해도 샘플링은 어렵다.</strong></p> <p>여기서 기각샘플링은 샘플들이 모집단의 확률밀도에 맞게 샘플링을 해주는 착한 알고리즘이다.</p> <h4 id="proposal-distribution-gx">Proposal Distribution \(g(x)\)</h4> <p>기각샘플링을 이해하기 위해 제안분포 (Proposal distribution) 이란 것을 알아야 한다. 제안분포 \(g(x)\) 는 명칭에서도 알 수 있듯이 수학자가 제안하는 분포다. 어떤 분포를 사용해도 좋지만, 타깃 분포와 유사한 분포, 혹은 샘플링을 쉽게 할 수 있는 분포를 사용하는게 일반적이다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/mcmc/two-480.webp 480w,/assets/img/posts/machinelearning/mcmc/two-800.webp 800w,/assets/img/posts/machinelearning/mcmc/two-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/mcmc/two.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>예시를 통해 설명해 보겠다. 위 그림을 참고하며 제안분포를 설정 후 타깃분포의 최고점을 감쌀 만큼 제안분포를 상수배 해주고 \((Mg(x))\), 제안 분포에서 랜덤한 값을 추출해서 해당 값과 해당 값에 대한 타깃분포의 값을 비교한다 (말이 헷갈리지만 그림에서 붉은 점선과 푸른 점선의 길이를 비교하는 것이다). 만약 타깃분포의 값이 더 크면 해당 샘플을 수용한다.</p> <p><strong>여기서 두개의 값들을 비교하는 것은 결국 랜덤값에 대한 두 분포의 Likelihood 를 비교하는 것이다.</strong></p> <blockquote> <p>Likelihood: \(P(x \mid \theta)\), or the <strong>probability of x in a given distribution.</strong></p> </blockquote> <p>이런 식으로 모든 데이터포인트에 대해 기각샘플링 알고리즘을 사용하면, 타깃 분포를 따르는 샘플들을 추출 할 수 있다. 기각샘플링은 효과적인 알고리즘이지만, 단점은 기각되는 데이터 포인트가 많기때문에 Computational Complexity 가 크다는 것이다. 이를 극복하기 위해 나온 알고리즘이 바로 해당 포스팅의 주제인 \(Markov \ Chain \ Monte \ Carlo \ Algorithm\) 이다 <del>빌드업</del>.</p> <h2 id="markov-chain-monte-carlo">Markov Chain Monte Carlo</h2> <p>Markov Chain: \(t-1\) 상태에서 \(t\) 로 넘어갈 때, \(t\) 가 \(t-1\) 으로부터만 직접적인 영향을 받는 프로세스를 Markov Chain 이라 한다.</p> <p>Monte Carlo: 무한한 계산으로만 정답을 알 수 있는 것을 유한한 시도만으로 통계적 정답을 추정하기 위한 시뮬레이션.</p> <p>이 두가지 아이디어를 합친 것이 MCMC 인데, 간단하게 생각하면 최대우도법과 기각샘플링 같은 <strong>파라미터 추정법과 샘플링 방식을 하나로 합친 알고리즘이다.</strong></p> <p>MCMC 는 이전에 언급한 베이지안 추론, 최대우도법, 그리고 기각샘플링에 기초하고 있고, MCMC는 다량의 세분화된 알고리즘이 있지만 동일한 pseudo-process 를 따른다.</p> <blockquote> <p>MCMC Pseudo-Process</p> <ol> <li>Random Initialization</li> <li>제안분포를 이용해 첫 sample 기반 다음 sample 을 추천 (Markov Chain 부분)</li> <li>특정 기준에 다라 추천된 sample 을 Accept/Reject</li> <li>Repeat.</li> </ol> </blockquote> <h4 id="mcmc---metropolis-algorithm-sampling">MCMC - Metropolis Algorithm (Sampling)</h4> <p>MCMC 알고리즘 중 가장 유명한 소분류 알고리즘인 Metropolis Algorithm 을 예시로 설명하겠다. 해당 그림에 그려진 <del>유사</del>확률밀도함수를 우리의 타깃 분포라고 가정하자.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/mcmc/three-480.webp 480w,/assets/img/posts/machinelearning/mcmc/three-800.webp 800w,/assets/img/posts/machinelearning/mcmc/three-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/mcmc/three.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <blockquote> <ol> <li>먼저 랜덤한 초기값을 고르고 \(x_0\) 이라 설정한다.</li> <li>\(x_0\) 을 평균으로 갖는 제안분포 \(g(x)\) 를 설정한다. <strong>이때 제안분포를 기각샘플링처럼 마음대로 정할 수 있지만, 예시로 설명하는 이 알고리즘은 제안분포를 대칭분포로 사용하는 Metropolis-Hastings 알고리즘이다.</strong></li> <li>초기값 \(x_0\) 을 기준으로 제안분포를 설정 한 뒤, 해당 제안분포에서도 랜덤한 샘플 \(x_1\) 을 추출한다. 타깃분포에 대한 이 두 샘플의 Likelihood 를 계산 한 뒤, \(x_1\) 의 Likelihood 가 \(x_0\) 보다 높다면 \(x_1\) 을 샘플로 Accept 한다.</li> <li>\(x_1\) 을 다시 \(x_0\) 로 설정한 뒤 반복한다.</li> </ol> </blockquote> <p>MCMC 의 과정을 보면 기각샘플링과 굉장히 유사하다. 하지만 차이점은 기각샘플링은 하나의 샘플에 대해서 타깃분포와 제안분포의 Likelihood 를 비교하는 반면, MCMC 샘플링에선 제안분포를 통해 다음 샘플을 추천받아 이전 샘플과 다음 샘플의 Likelihood 를 비교한다. 여기서 다음 샘플이 이전 샘플에 따라 추출이 되기 때문에 Markov Chain 이란 이름이 붙은 것이다.</p> <p>여기서 약간 의문점이 들 수도 있는게, 샘플을 기각하다 보면 샘플링 되는 값들은 타깃분포의 한 optima 로 수렴할 것이다. 이를 방지하기 위해 MCMC 에선 일종의 <strong>패자부활전</strong> 을 진행한다.</p> <table> <thead> <tr> <th>기준</th> <th>function</th> </tr> </thead> <tbody> <tr> <td>Accept</td> <td>\(\frac {f(x_1)}{f(x_0)}&gt;1 \ or &gt; u\)</td> </tr> <tr> <td>Reject</td> <td>\(\frac {f(x_1)}{f(x_0)}&lt;1 \ and &lt; u\)</td> </tr> </tbody> </table> <p>만약 \(x_0, x_1\) 두 샘플의 Likelihood를 나눈 값이 1을 넘지 못한다면 (\(x_1\) 의 Likelihood 가 \(x_0\)보다 작다면) \(x_1\) 을 바로 reject 하는 것이 아니고 uniform distribution 을 이용해서 MCMC 의 프로세스를 한번 더 수행한다. Uniform dist. 에서 랜덤한 값 \(u\) 를 추출하고, 만약 \(x_0, x_1\) 에 대한 Likelihood 를 나눈 값이 이 랜덤한 값 \(u\) 보다 크면 \(x_1\) 을 Accept 한다.</p> <p>\(x_0, x_1\) 에 대한 Likelihood 를 나눈 값이 이 랜덤한 값 \(u\) 보다 작으면 \(x_1\) 을 reject 하지만, 샘플링이 되지 않을 뿐 \(x_1\) 은 버려지지 않고 새로운 제안분포를 설정하기 위해 \(x_0\) 값으로 update 된다.</p> <p><strong>정리를 하자면 두 샘플값에 대한 Likelihood 를 비교한 값이 1 혹은 \(u\) 보다 크면 그 샘플을 Accept 하고, 1 혹은 \(u\) 보다 작으면 그 샘플을 Reject 한다.</strong></p> <h4 id="pseudocode">Pseudocode</h4> <blockquote> <ol> <li>Initialize \(x_0\)</li> <li>for \(i = 0\) to \(N-1\)</li> </ol> <p>Sample \(u \sim U_{[0,1]}\)</p> <p>Sample \(x_{new} \ g(x_{new} \mid x_i)\)</p> <p>if \(u &lt; A(x_i,x_{new} = min(1, \frac {f(x_{new})}{f_(x_i)}))\)</p> <p>    \(x_{i+1} = x_{new}\)</p> <p>else</p> <p>    \(x_{i+1} = x_i\)</p> </blockquote> <p>지금까지 예시로 설명한 알고리즘은 MCMC 의 Metropolis 알고리즘으로, 제안분포를 대칭분포로 설정하고 진행하는 알고리즘이다. 만약 기각샘플링에서 잠깐 언급한 것 처럼 타깃분포와 유사한 분포로 제안분포를 설정하고 싶다면 Metropolis 알고리즘을 조금 변형한 Metropolis-Hastings 알고리즘을 사용하면 된다.</p> <h4 id="mcmc---bayesian-estimation-algorithm">MCMC - Bayesian Estimation Algorithm</h4> <p>MCMC Metropolis 가 기각샘플링 같은 샘플링 방법이라면, 지금 살펴볼 MCMC Bayesian Estimation 은 최대우도법과 같은 파라미터 추정 알고리즘이다.</p> <p>최대우도법과 MCMC Bayesian Estimation 의 차이는 최대우도법에선 모든 \(x\)에 대해 Likelihood 를 점검하지만, MCMC Bayesian Estimation 에선 제안분포를 통해 관찰하고자 하는 파라미터값을 제안받아서 점검한다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/mcmc/four-480.webp 480w,/assets/img/posts/machinelearning/mcmc/four-800.webp 800w,/assets/img/posts/machinelearning/mcmc/four-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/mcmc/four.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>동일하게 예시로 설명을 해보겠다. 여기 총 population 이 3만인 모집단에서 샘플링한 표본집단의 분포가 있다. 이 분포를 통해 모집단의 파라미터인 평균을 추정하려면 MCMC Bayesian Estimation 을 사용하면 된다.</p> <blockquote> <ol> <li>MCMC Metropolis 와 동일하게 먼저 랜덤한 파라미터값 \(\theta\) 를 초기화한다.</li> <li>이 랜덤한 파라미터값을 기준으로 제안분포를 설정하고, 이 제안분포로 새로운 파라미터 값을 추천받는다.</li> <li>이 두 파라미터 값에 대한 타깃분포를 비교할 때, \(f_{new}(x)/f_{old}(x) &gt; 1\) 이면 해당 파라미터를 Accept 한다.</li> </ol> </blockquote> <p>여기서 샘플링 알고리즘과의 차이점은 타깃함수의 파라미터가 변경된 경우를 비교하는것이다. 파라미터가 변경된다는 것은 타깃분포 자체가 동적으로 바뀐다는 것인데, 샘플링 알고리즘에선 타깃분포는 변하지 않는다.</p> <p>Accept 되는 기준식을 풀어서 써보면 처음에 등장한 베이즈 정리로 값을 구할 수 있다. 파라미터의 타깃분포에 대한 확률은 \(P(\theta \mid Data)\) 로 쓸 수 있고, 이것이 사후확률이라면 베이즈 정리를 통해 사전확률에 대한 공식으로 풀어낼 수 있다.</p> <p><strong>결국 MCMC Bayesian Estimation 에서 \(\theta\) 가 Accept 되는 기준은 베이즈 정리를 통한 Likelihood * Prior 값이 되는것을 알 수 있다.</strong></p> <blockquote> \[\frac{f_{new}(x)}{f_{old}(x)} &gt; 1\] \[\frac{P(\theta = \theta_{new} \mid Data)}{P(\theta = \theta_{old} \mid Data)}&gt;1\] \[\frac{f(D \mid \theta=\theta_{new})P(\theta=\theta_{new})/f(D)} {f(D \mid \theta=\theta_{old})P(\theta=\theta_{old})/f(D)}&gt;1\] \[\frac{f(D \mid \theta=\theta_{new})P(\theta=\theta_{new})} {f(D \mid \theta=\theta_{old})P(\theta=\theta_{old})}&gt;1\] \[f(D \mid \theta) = \prod_{i=1}^N f(d_i \mid \theta)\] <p>$\frac{f(D \mid \theta=\theta_{new})P(\theta=\theta_{new})} {f(D \mid \theta=\theta_{old})P(\theta=\theta_{old})}&gt;1$</p> <p>$\frac{f(D \mid \theta=\theta_{new})P(\theta=\theta_{new})} {f(D \mid \theta=\theta_{old})P(\theta=\theta_{old})}&gt;1$</p> \[\prod_{i=1}^{N}\frac{1}{\sigma\sqrt{2\pi}}\exp\left(-\frac{(d_i-\mu)^2}{2\sigma^2}\right)\] \[\sum_{i=1}^{N}\left\lbrace\log\left(\frac{1}{\sigma\sqrt{2\pi}}\right)-\frac{(d_i-\mu)^2}{2\sigma^2}\right\rbrace\] \[\sum_{i=1}^{N}\left\lbrace-\log(\sigma\sqrt{2\pi})-\frac{(d_i-\mu)^2}{2\sigma^2}\right\rbrace\] <p>$\frac{\sum_{i=1}^{N}\left\lbrace-\log(\sigma\sqrt{2\pi})-\frac{(d_i-\mu_{new})^2}{2\sigma^2}\right\rbrace + \log(P(\mu = \mu_{new}))} {\sum_{i=1}^{N}\left\lbrace-\log(\sigma\sqrt{2\pi})-\frac{(d_i-\mu_{old})^2}{2\sigma^2}\right\rbrace + \log(P(\mu = \mu_{old}))} &gt; 1$</p> </blockquote> <h4 id="references">References</h4> <ul> <li><a href="https://arxiv.org/pdf/1909.12313.pdf">A Conceptual Introduction to Markov Chain Monte Carlo Methods</a></li> <li><a href="https://angeloyeo.github.io/2020/09/17/MCMC.html">공돌이의 수학노트: Markov Chain Monte Carlo</a></li> <li><a href="https://towardsdatascience.com/bayesian-inference-and-markov-chain-monte-carlo-sampling-in-python-bada1beabca7">Bayesian Inference and Markov Chain Monte Carlo Sampling in Python</a></li> <li><a href="https://github.com/chi-feng/mcmc-demo">The Markov-chain Monte Carlo Interactive Gallery</a></li> </ul>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Generative Adversarial Networks (Goodfellow et al. 2014)</title><link href="https://tomtom1103.github.io/blog/2022/gan/" rel="alternate" type="text/html" title="Generative Adversarial Networks (Goodfellow et al. 2014)"/><published>2022-08-01T00:00:00+00:00</published><updated>2022-08-01T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/gan</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/gan/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>Introduction</li> <li>Generative Models</li> <li> <p>Objective function of GAN</p> <ul> <li>Discriminator’s Perspective: Maximize</li> <li>Generator’s Perspective: Minimize</li> </ul> </li> <li>Global Optimality</li> </ul> <h2 id="introduction">Introduction</h2> <p>GAN 은 Goodfellow 와 Bengio 등 저명한 딥러닝 연구자들이 2014년 처음 고안한 후, 딥러닝에 대한 대중의 이목을 크게 끈 새로운 생성 모델이다. 굉장히 단순하면서도 아름다운 목적함수를 통해 딥러닝의 capability 에 대한 새로운 패러다임을 제시했으며, 반대로 실전에서 학습시키기 굉장히 어려운 모델로 악명이 높기도 하다. GAN 은 2022년 현재 폭발적인 연구와 함께 고도성장했으며, <a href="https://thispersondoesnotexist.com">This Person Does Not Exist</a> 와 같은 일반인이 구분하기 불가능할 정도로 사실적인 샘플을 생성할 수 있다. StyleGAN, SinGAN, BEGAN, DCGAN 등 특정 분야에서 고도화 된 모델들은 논문이 나오는 속도를 따라잡을 수 없을 정도로 다양하지만 그 시작은 Goodfellow 의 <a href="https://arxiv.org/abs/1406.2661">Generative Adversarial Networks</a> 였다.</p> <p>GAN 을 처음 접할 때 가장 많이 드는 예시는 위조지폐범과 경찰의 예시다. 위조지폐범은 처음엔 지폐를 위조하는 법을 모르지만, 경찰에게 발각되는 과정을 거치며 점점 더 정교한 지폐를 위조하게 되고, 결국 경찰마저 속이는 실력을 학습한다는 간단하면서도 직관적인 모델 설명이다.</p> <blockquote> <p>모든 강의와 모델 설명에서 똑같은 예시를 들기에 다들 약속이나 한줄 알았지만 본 논문에서 직접 든 예시였다.</p> </blockquote> <p>GAN 은 \(G\) (Generator, 생성자), \(D\) (Discriminator, 판별자) 두개의 모델을 동시에 학습하며 \(G\) 는 \(D\)를 속이기 위해, 그리고 \(D\)는 \(G\)를 잡기 위해 학습이 된다. 이때 GAN 은 다른 생성모델에서 사용하는 마르코브 체인과 같은 stochastic 과정이 필요 없고, 딥러닝에서 익숙한 역전파를 통해 학습된다. 새로운 샘플을 생성할 때 순전파만 사용하기에 굉장히 빠르다는 장점 또한 있다.</p> <h2 id="generative-models">Generative Models</h2> <p>우리가 익숙한 지도학습 모델들은 정답 라벨을 통해 샘플스페이스 속 데이터를 구분짓는 분류기를 학습하지만, 생성모델은 데이터의 실제 분포를 학습한다. 만약 생성모델이 데이터의 분포를 학습한다면, 해당 분포에서 확률이 제일 높은 지점에서 샘플을 추출하면 실제 데이터와 유사할 것이다. 이때 GAN 의 \(G\) 는 데이터의 실제 분포를 학습하고, \(D\) 는 \(G\) 가 생성한 샘플을 진짜인지 가짜인지 판별한다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/paper/gan/img1-480.webp 480w,/assets/img/posts/paper/gan/img1-800.webp 800w,/assets/img/posts/paper/gan/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/paper/gan/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>위 이미지에서 초록 분포는 생성모델 \(G\)의 분포이며, 실제 분포는 검정 점선이다. \(G\)는 latent domain 에서 sample \(z\) 를 추출하여 실제 데이터의 분포인 \(x\) 로 매핑하며, \(D\) 는 해당 샘플이 진짜면 1, 가짜면 0을 리턴하도록 학습한다.</p> <p>a. 처음엔 \(G\) 는 학습이 되어있지 않아 실제 데이터 분포와 많이 다르고, \(D\) 도 학습이 잘 되어있지 않아 전반적으로 fluctuate 한다. 그럼에도 실제 데이터 분포가 내려가고 \(G(z)\) 가 올라가는 시점엔 \(D\) 는 비교적 낮게 Probability 를 측정한다.</p> <p>b. 논문에선 GAN 을 학습시킬 때 \(D\) 를 먼저 학습한다. 그렇기에 전반적으로 실제 데이터 분포에 대한 P 를 균등하게 측정하고, \(G(z)\) 에 대해 거의 0에 가깝게 P 를 측정한다.</p> <p>c. \(D\) 를 학습 후 \(G\) 를 학습하면, \(G(z)\) 의 분포가 실제 데이터 분포와 유사해진다.</p> <p>d. 최종적으로 \(G\) 가 완벽히 실제 데이터 분포를 학습한다면, \(D\) 는 샘플이 실제 데이터인지 \(G(z)\) 인지 판별하지 못하기에 P 를 uniform 하게 0.5 로 측정한다.</p> <p>최종적으로 \(G\)가 잘 학습이 된다면, \(G\) 의 분포에서 데이터 점이 아닌 부분을 추출하면 이전에 없었던 새로운 데이터가 생성되는 것이다. 즉, 우리가 알고 있는 인퍼런스 과정은 \(G\) 만 사용하는 것이다.</p> <h2 id="objective-function-of-gan">Objective function of GAN</h2> \[\min _{G} \max _{D} V(D, G)=E_{x \sim p_{\text {data }}(x)}[\log D(x)]+E_{z \sim p_{z}(z)}[\log (1-D(G(z)))]\] <p>GAN 의 목적함수 \(V\) 는 굉장히 단순하면서도 명쾌하다.</p> <ul> <li>\(D\) : Discriminator</li> <li>\(G\) : Generator</li> <li>\(x \sim p_{\text {data }}(x)\) : 실제 데이터 분포에서 샘플 \(x\) 를 추출</li> <li>\(z \sim p_{z}(z)\) : 노이즈 분포에서 latent vector \(z\) 를 추출</li> </ul> <p>GAN 의 목적함수는 game theory 의 two player minmax game 에 기반한다. \(G\) 에 대해 목적함수 값을 최소화 함과 동시에 \(D\) 에 대해 목적함수의 값을 최대화 하는것이다. \(G(z)\) 는 새로운 데이터 인스턴스를 생성하고 (MNIST 데이터라면 28x28 array), \(D(x)\) 는 \(x\) 가 실제 분포에서 나왔을 확률 (0~1) 을 리턴한다. 이 사실을 알고 \(D\) 의 관점에서 목적함수를 해체해보자.</p> <h3 id="discriminators-perspective-maximize">Discriminator’s Perspective: Maximize</h3> <p>\(D\) 는 자신이 받는 인풋이 실제 데이터 \(x\) 이면 1을 리턴해야 하고, \(G(z)\) (가짜 데이터) 면 0을 리턴해야 한다.</p> \[E_{x \sim p_{\text {data }}(x)}[\log D(x)]\] <p>그렇기에 \(x\) 가 실제 데이터에서 왔다면, 목적함수의 앞부분은 이를 maximize 하는 역할을 한다.</p> \[E_{z \sim p_{z}(z)}[\log (1-D(G(z)))]\] <p>반대로 \(D(G(z))\) 에 대해 0에 가까운 확률을 리턴해야 한다. \(D(G(z))\) 가 작을수록 \(log(1-D(G(z)))\) 는 커지기 때문에 목적함수의 뒷부분은 이를 maximize 하는 역할을 한다.</p> \[+\nabla_{\theta_{d}} \frac{1}{m} \sum_{i=1}^{m}\left[\log D\left(\boldsymbol{x}^{(i)}\right)+\log \left(1-D\left(G\left(\boldsymbol{z}^{(i)}\right)\right)\right)\right]\] <p>그렇기에 학습을 진행 할 때 1차 도함수의 양의 방향으로 학습을 진행한다.</p> <h3 id="generators-perspective--minimize">Generator’s Perspective : Minimize</h3> <p>반대로 \(G\) 는 목적함수에 대해서 최소화 해야 한다. 목적함수의 앞부분은 \(G\)가 없기 때문에 상수취급을 할 수 있으므로, 결국 목적함수의 뒷부분만 남는다.</p> \[E_{z \sim p_{z}(z)}[\log (1-D(G(z)))]\] <p>\(G\) 는 \(D\)를 속이는것이 목표다. \(D\) 가 ‘속는다’ 라는 표현은 곧 \(D(G(z))\) 가 1에 가까워지는 것을 의미하므로, 목적함수를 minimize 하는것이 된다.</p> \[-\nabla_{\theta_{g}} \frac{1}{m} \sum_{i=1}^{m} \log \left(1-D\left(G\left(\boldsymbol{z}^{(i)}\right)\right)\right)\] <p>그렇기에 학습을 진행 할 때 1차 도함수의 음의 방향으로 학습을 진행한다.</p> <h2 id="global-optimality">Global Optimality</h2> <p>결국 GAN 은 위와 같은 간단한 목적식을 통해 생성자를 학습시킨다. 생성자를 학습시킨다는 것은 결국 생성자의 분포와 실제 분포가 같아진다는 것을 의미하는데, 논문은 이에 대해 증명을 한다.</p> <p><strong>명제:</strong> \(G\) 가 고정된 상황에서 \(D\) 의 optima 는 \({p_{data}(x)\over p_{data}(x)+ p_g(x)}\) 이다.</p> <p><strong>증명:</strong> 목적식에서 Expectation 을 공식으로 바꿔보면 다음과 같다: (\(E = \int xf(x)dx\))</p> \[\begin{aligned} V(G, D) &amp;=\int_{\boldsymbol{x}} p_{\mathrm{data}}(\boldsymbol{x}) \log (D(\boldsymbol{x})) d x+\int_{\boldsymbol{z}} p_{\boldsymbol{z}}(\boldsymbol{z}) \log (1-D(g(\boldsymbol{z}))) d z \end{aligned}\] <p>이때 \(D\) 의 입장에서 \(G(z)\) 나 \(x\) 는 그저 판별해야하는 인풋일 뿐이기에, \(g(z)=x\) 다. 그렇다면 위의 식을 하나의 적분식으로 표현 할 수 있다.</p> \[\begin{aligned} V(G, D) &amp;=\int_{\boldsymbol{x}} p_{\mathrm{data}}(\boldsymbol{x}) \log (D(\boldsymbol{x}))+p_{g}(\boldsymbol{x}) \log (1-D(\boldsymbol{x})) d x \end{aligned}\] <p>이때 위 식은 \(y = alog(y)+blog(1-y)\) 의 꼴을 띄고 있다. 이 식의 maximum 은 \([0,1]\) 사이에서 \(a\over a+b\) 이기 때문에, \(D\) 의 optima 또한 \({p_{data}(x)\over p_{data}(x)+ p_g(x)}\) 이다.</p> <p>위의 증명을 통해 최종적으로 \(p_g=p_{data}\) 인 것을 증명할 수 있다.</p> <p><strong>명제:</strong> Global optimum 은 \(p_g=p_{data}\) 이다.</p> <p><strong>증명:</strong> \(G\) 가 고정된 상황에서 \(G\) 에 대한 새로운 학습 criterion 함수 \(C\) 를 정의한다.</p> \[\begin{aligned} C(G) &amp;=\max _{D} V(G, D) \\ &amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{z} \sim p_{\boldsymbol{z}}}\left[\log \left(1-D_{G}^{*}(G(\boldsymbol{z}))\right)\right] \\ &amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }} a}\left[\log D_{G}^{*}(\boldsymbol{x})\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \left(1-D_{G}^{*}(\boldsymbol{x})\right)\right] \\ &amp;=\mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{p_{\text {data }}(\boldsymbol{x})}{P_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \frac{p_{g}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right] \end{aligned}\] <p>첫번째 명제에서 얻은 \({p_{data}(x)\over p_{data}(x)+ p_g(x)}\) 를 대입한 형태로 \(C(G)\) 를 표현한다.</p> \[\begin{aligned} C(G)= \mathbb{E}_{\boldsymbol{x} \sim p_{\text {data }}}\left[\log \frac{2*p_{\text {data }}(\boldsymbol{x})}{P_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right]+\mathbb{E}_{\boldsymbol{x} \sim p_{g}}\left[\log \frac{2* p_{g}(\boldsymbol{x})}{p_{\text {data }}(\boldsymbol{x})+p_{g}(\boldsymbol{x})}\right] - log(4) \end{aligned}\] <p>이때 약간의 수학적인 trick 을 이용해 앞단과 뒷단에 2를 곱한 뒤, \(log(4)\) 를 빼줌으로써 이를 상쇄시킨다.</p> \[C(G)= K L\left(p_{\text {data }} \| p_{g}\right)=\int_{-\infty}^{\infty} p_{\text {data }}(x) \log \left(\frac{p_{\text {data }}(x)}{p_{g}(x)}\right) d x\] <p>이때 식의 앞단과 뒷단은 KL Divergence 의 공식과 형태가 같아지기 때문에, 이를 KL Divergence 형태로 표현한다.</p> \[C(G)= \left.K L\left(p_{\text {data }} \| \frac{\mathrm{p}_{\text {data }}(\mathrm{x})+\mathrm{p}_{\mathrm{g}}(\mathrm{x})}{2}\right)\right)+K L\left(p_{g} \| \frac{\mathrm{p}_{\mathrm{data}}(\mathrm{x})+\mathrm{p}_{\mathrm{g}}(\mathrm{x})}{2}\right)-\log (4)\] <p>KL Divergence 는 두 분포의 유사도를 측정하는데 사용하지만 distance metric 으로 사용하긴 어렵기에 Jensen-Shannon Divergence 로 치환한다.</p> \[C(G)= 2*JSD(p_{data}||p_g) - log(4)\] <p>JSD 는 distance metric 이므로 \(p_g=p_{data}\) 일때 JSD=0 이다. 그렇기에 \(C(G)\) 의 global optimum 은 \(-log(4)\) 이며, 유일한 해답은 \(p_g=p_{data}\) 이다.</p>]]></content><author><name></name></author><category term="papers"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Dimensionality Reduction - Isomap (Isometric Feature Mapping)</title><link href="https://tomtom1103.github.io/blog/2022/isomap/" rel="alternate" type="text/html" title="Dimensionality Reduction - Isomap (Isometric Feature Mapping)"/><published>2022-07-10T00:00:00+00:00</published><updated>2022-07-10T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/isomap</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/isomap/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>Isometric Feature Mapping (Isomap)</li> <li>Step 1: Construct Neighborhood graph</li> <li>Step 2: Compute the Shortest Path</li> <li>Step 3: Construct \(d\) - dimensional Embedding with MDS</li> </ul> <h2 id="isometric-feature-mapping-isomap">Isometric Feature Mapping (Isomap)</h2> <p>대표적인 선형변환 차원축소 방법론엔 PCA (주성분분석) 와 MDS (다차원척도법) 가 있다면, 대표적인 비선형변환 차원축소 방법론엔 Isomap 과 LLE 가 있다. 두 방법론은 같은 연도의 같은 Journal 의 같은 권호수에 출판되었으며, 위상수학의 manifold 를 머신러닝에 접목시킨 manifold learning 의 주역이 되기도 했다. 두 방법론 중 Isomap 에 대해 먼저 알아보자.</p> <p>선형변환 차원축소 방법론 (PCA, MDS) 는 computational complexity 가 낮고 전역최적해를 보장해준다는 장점이 있지만, 데이터가 애초에 선형성을 띄고 있지 않는다면 결과가 좋지 못하다는 단점이 있다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/isomap/img1-480.webp 480w,/assets/img/posts/machinelearning/isomap/img1-800.webp 800w,/assets/img/posts/machinelearning/isomap/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/isomap/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>위 이미지의 그림 A 를 보자. 데이터는 3차원의 공간에 있으며, 2차원의 직사각형을 돌돌 만 Roll 형태를 띄고 있다. 해당 데이터에 MDS 를 적용하여 거리에 대한 정보를 보존하며 낮은 차원으로 차원축소를 했다고 가정하자. 이때 검은 점과 푸른 점은 실제 3차원 공간에서도 꽤나 가깝기 때문에, euclidean distance 를 proximity measure 로 정의한 MDS 상 아무런 문제가 되지 않는다. 하지만 이런식으로 차원축소를 한다면 <strong>intrinsic dimension 의 정보가 사라진다는 치명적인 단점이 있다.</strong></p> <p>Intrinsic dimension 이란 데이터가 위치한 내재적인 차원을 의미하고, intrinsic dimension 을 펼친 공간을 manifold 라고 한다. 검은 점을 기준으로 푸른 점과의 euclidean 거리는 붉은 점보다 가깝지만, 실제 manifold 상 거리를 어림짐작한다면 푸른 점은 훨씬 멀리 떨어져 있다. <strong>그렇기에 Isomap 의 핵심 아이디어는 보존하고자 하는 거리 정보를 Intrinsic manifold 상의 거리로 정의하여 차원축소를 진행하는 것이다.</strong></p> <p>두번째 그림 B 는 객체를 node 로 취급하고 이웃들끼리 edge 를 그려 그래프 구조를 통해 intrinsic manifold 의 구조를 최대한 보존한 것이다. Intrinsic manifold 상 두 객체간의 거리를 알고싶다면 그려진 그래프를 따라 최단 경로로 이동하면 된다. 그림 C 를 보면 manifold 를 펼쳐놓은 것인데, 이때 manifold 상 실제 최단거리는 푸른색 직선이고, 이를 최대한 비슷하게 따라간 길이 붉은색으로 표시된 그래프를 통해 따라간 길이다.</p> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">Proximity Measure</th> </tr> </thead> <tbody> <tr> <td style="text-align: center"><strong>MDS</strong></td> <td style="text-align: center">Original Space 의 최단거리 (Euclidean, Manhattan) 혹은 유사도 (Cosine, Jaccard)</td> </tr> <tr> <td style="text-align: center"><strong>Isomap</strong></td> <td style="text-align: center">Intrinsic Manifold 속 그래프 상 최단거리</td> </tr> </tbody> </table> <p>Intrinsic Manifold 의 개념을 이해했다면 Isomap 은 굉장히 단순해진다.</p> <h3 id="step-1-construct-neighborhood-graph">Step 1: Construct Neighborhood graph</h3> <p>Manifold 상 거리를 표현하기 위해 객체들을 연결해주는 그래프를 구해야 한다. 이때 하나의 점을 이웃들과 연결시키는 방법은 크게 두가지다.</p> <p><strong>Epsilon Neighborhood</strong></p> <p>DBSCAN 에서도 clustering 으로 사용하는 epsilon neighborhood 는 정의해둔 radius \(\epsilon\) 안에 존재하는 점들을 모두 연결시키는 방법론이다.</p> <p><strong>K-Nearest Neighbor</strong></p> <p>K-NN 은 한 점에서 가장 가까운 \(k\) 개의 점을 연결시키는 방법론이다.</p> <blockquote> <p>두개의 방법론 모두 타당하지만, 결국 임의의 두 객체간의 거리를 전부 계산해야 하기 때문에 객체 단 하나라도 path 가 끊겨있으면 안된다. 그렇기에 일반적으론 K-NN 이 사용되지만 K-NN 또한 ‘short circuit errors’ 의 문제가 있다. Short circuit errors 란 \(k\) 가 너무 커 실제 manifold 의 정보보다 과하게 객체들을 연결시키는 에러다.</p> </blockquote> <h3 id="step-2-compute-the-shortest-path">Step 2: Compute the Shortest Path</h3> <p>모든 점들이 연결되었다면 모든 객체들에 대한 graph 상 서로간의 거리를 계산해야 한다. 이때 각 객체는 기존 차원에서 euclidean distance 로 그래프가 연결 되어있기 때문에, 알고리즘 수업에서 배운 그 어떤 최단거리 알고리즘을 사용할 수 있다. 대표적으론 Dijkstra Algorithm, Bellman-Ford Algorithm, Floyd-Warshall Algorithm 이 있다.</p> <blockquote> <p>개인적으론 다익스트라 알고리즘을 좋아한다. 비교적 낮은 time complexity 를 갖기도 하고, 처음 배웠을 때 이름이 \(D_{ijk}\)stra (\(i,j,k\) 간의 \(Distance\)) 로 보였기 때문이다. 에르허츠 다익스트라의 어록들도 한몫한다.</p> <p>“The question of whether a computer can think is no more interesting than the question of whether a submarine can swim.” - <a href="https://en.wikipedia.org/wiki/Edsger_W._Dijkstra">Edsger W. Dijkstra</a></p> </blockquote> <h3 id="step-3-construct-d---dimensional-embedding-with-mds">Step 3: Construct \(d\) - dimensional Embedding with MDS</h3> <p>그래프를 구축하고 각 객체간의 그래프상 최단거리를 Proximity matrix \(\mathbf{D}\) 로 정의한 뒤, 기본적인 Multi-Dimensional Scaling 을 진행하면 된다. 즉, Isomap 은 객체간 거리를 intrinsic manifold 상의 거리로 정의한 것 뿐이지, 저차원으로 embedding 하는 과정은 MDS 와 다름없다. 하지만 intrinsic manifold 로 거리를 정의했기 때문에, 본질적인 거리정보가 traditional MDS 보다 많이 보존된다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/isomap/img2-480.webp 480w,/assets/img/posts/machinelearning/isomap/img2-800.webp 800w,/assets/img/posts/machinelearning/isomap/img2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/isomap/img2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>위 예시는 선형변환 차원축소방법론인 PCA 와 Isomap 의 결과의 시각화이다. 궁극적인 task 가 classification 이라면 Isomap 이 우월한 방법론인 것을 알 수 있다.</p> <blockquote> <p>해당 포스트는 강필성 교수님의 <a href="https://github.com/pilsung-kang/Business-Analytics-IME654-">Business Analytics</a> 를 참고하여 작성되었습니다.</p> </blockquote>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Dimensionality Reduction - MDS (Multi-Dimensional Scaling)</title><link href="https://tomtom1103.github.io/blog/2022/mds/" rel="alternate" type="text/html" title="Dimensionality Reduction - MDS (Multi-Dimensional Scaling)"/><published>2022-07-09T00:00:00+00:00</published><updated>2022-07-09T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/mds</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/mds/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li> <p>Multi-Dimensional Scaling (MDS)</p> <ul> <li>Step 1: Proximity Matrix</li> <li>Step 2: Extracting Coordinates</li> </ul> </li> </ul> <h2 id="multi-dimensional-scaling-mds">Multi-Dimensional Scaling (MDS)</h2> <p>Multi-Dimensional Scaling (MDS), 혹은 다차원척도법은 주성분분석(PCA) 과 함께 대표적인 선형변환 차원축소 방법론/변수추출기법이다. <strong>PCA 가 데이터의 분산을 최대한 보존하며 낮은 차원으로 데이터를 사영했다면, MDS 는 객체들간 거리를 최대한 보존하며 낮은 차원으로 데이터를 투영시킨다.</strong> 그렇기에 MDS 의 최종 목표는 객체들간의 거리를 최대한 보존하는 좌표계를 찾는 것이다.</p> <table> <thead> <tr> <th style="text-align: center"> </th> <th style="text-align: center">Principal Component Analysis</th> <th style="text-align: center">Multi-Dimensional Scaling</th> </tr> </thead> <tbody> <tr> <td style="text-align: center">Data</td> <td style="text-align: center">\(n\) objects in a \(d\) dimensional space</td> <td style="text-align: center">Proximity matrix between \(n\) objects</td> </tr> <tr> <td style="text-align: center">Purpose</td> <td style="text-align: center">Find a set of bases to preserve the original variance</td> <td style="text-align: center">Find a set of coordinates that preserve the distance information between objects</td> </tr> <tr> <td style="text-align: center">Output</td> <td style="text-align: center">\(d\) bases (eigenvectors) and eigenvalues</td> <td style="text-align: center">Coordinate of each object in \(d\) dimensional space</td> </tr> </tbody> </table> <blockquote> <p><strong>Coverage, 혹은 범용성은 PCA 보다 MDS 가 높다.</strong></p> <p>MDS 가 기본적으로 사용하는 것은 데이터의 Proximity Matrix \(\mathbf{D}\) 이고, 이는 기존 데이터에서 쉽게 구축 할 수 있기 때문이다. 그렇기에 MDS 로 \(\mathbf{D \Rightarrow X}\) 는 가능하지만 다른 방법론으론 어렵다.</p> <p>MDS: \(\mathbf{D \Rightarrow X \Rightarrow \lambda}\)</p> <p>PCA: \(\mathbf{X \Rightarrow \lambda}\)</p> </blockquote> <h3 id="step-1-proximity-matrix">Step 1: Proximity Matrix</h3> <p>기존 데이터셋인 \(\mathbf{X} \ (d\times n)\) 이 있다면, 객체간의 거리를 정의하여 대칭행렬 \(\mathbf{D} \ (n\times n)\) 을 만들 수 있다. 이때 객체간의 거리는 Euclidean, Manhattan Distance 같은 기본적인 거리로 정의할 수 있으며, 거리 대신 Correlation, Jaccard 같은 유사도로도 정의 할 수 있다. 이때 \(\mathbf{D}\) 에 대한 제약은 다음과 같다.</p> \[d_{ij} \geq 0, \ d_{ii} = 0, \ d_{ij} = d_{ji} \\ d_{ij} \leq d_{ik}+d_{kj}\] <p>\(\mathbf{D}\) 는 모든 객체들이 0보다 크거나 같은 값을 갖고 대각성분이 0 인 대칭행렬임을 첫째줄에서 표현하고, 삼각부등식의 제약 또한 만족해야 한다.</p> <p>\(\mathbf{D}\) 에서 임의의 두 객체들간의 거리는 다음과 같은 공식으로 계산할 수 있다. 이때 객체라 함은 데이터셋 \(\mathbf{X}\) 의 각 샘플이다.</p> \[d^2_{rs} = (\mathbf{x_r - x_s})^T(\mathbf{x_r - x_s})\] <p>즉, 샘플 \(r,s\) 간의 거리의 제곱은 위와 같은 행렬식으로 계산되는 스칼라값이다.</p> <h3 id="step-2-extracting-coordinates">Step 2: Extracting Coordinates</h3> <p>각 샘플이 \(d^2_{rs} = (\mathbf{x_r - x_s})^T(\mathbf{x_r - x_s})\) 인 객체들간의 거리정보를 담고 있는 행렬 \(\mathbf{D}\) 를 구축했다. \(\mathbf{D}\) 로부터 바로 \(\mathbf{X}\) 를 구할 수 없기 때문에 임의의 행렬 \(\mathbf{B}\) 를 만든다. 이때 \(\mathbf{B}\) 는 \(\mathbf{D}\) 의 모든 샘플에 대한 내적값으로 채워진다.</p> \[\mathbf{[B]}_{rs} = b_{rs} = \mathbf{x^T_r x_s}\] <p>이때 모든 변수 \(p\) 의 평균은 0이라고 가정한다.</p> \[\sum_{r=1}^{n} x_{r i}=0,(i=1,2, \ldots, p) \quad d_{r s}^{2}=\mathbf{x}_{r}^{T} \mathbf{x}_{r}+\mathbf{x}_{s}^{T} \mathbf{x}_{s}-2 \mathbf{x}_{r}^{T} \mathbf{x}_{s}\] <p>샘플 \(r, s\) 간의 거리의 제곱식을 전개하면 우측과 같은 식으로 표현할 수 있다.</p> \[\begin{gathered} b_{r s}=\mathbf{x}_{r}^{T} \mathbf{x}_{s}=-\frac{1}{2}\left(d_{r s}^{2}-\frac{1}{n} \sum_{s=1}^{n} d_{r s}^{2}-\frac{1}{n} \sum_{r=1}^{n} d_{r s}^{2}+\frac{1}{n^{2}} \sum_{r=1}^{n} \sum_{s=1}^{n} d_{r s}^{2}\right) \\ =a_{r s}-a_{r .}-a_{\cdot s}+a_{. .} \\ \left(\text {where } a_{r s}=-\frac{1}{2} d_{r s}^{2}, a_{r .}=\frac{1}{n} \sum_{s} a_{r s}, a_{\cdot s}=\frac{1}{n} \sum_{r} a_{r s}, a_{. .}=\frac{1}{n^{2}} \sum_{r} \sum_{s} a_{r s}\right) \\ {[\mathbf{A}]_{r s}=a_{r s} \quad \mathbf{B}=\mathbf{H A H} \quad \mathbf{H}=\mathbf{I}-\frac{1}{n} \mathbf{1 1} ^{T}} \end{gathered}\] <p>수학적인 트릭을 이용해 임의의 행렬 \(\mathbf{B}\) 를 위와 같이 전개할 수 있으며, 최종적인 좌표계 행렬 \(\mathbf{X}\) 는 \(\mathbf{X = V_1\Lambda_1^{1 \over 2}}\) 가 된다.</p> <blockquote> <p>사실 MDS 에서 좌표계 행렬 \(\mathbf{X}\) 을 구하는 과정은 이보다 훨씬 복잡하다. 요즘 MDS 는 그저 단일 차원축소 방법론으로 사용하지 않지만, ISOMAP 의 기본 연산이 되기 때문에 Proximity/Distance Matrix \(\mathbf{D}\) 에서 저차원의 좌표계 \(\mathbf{X}\) 로 투영되는 개념을 알아가면 좋다.</p> </blockquote> <blockquote> <p>해당 포스트는 강필성 교수님의 <a href="https://github.com/pilsung-kang/Business-Analytics-IME654-">Business Analytics</a> 를 참고하여 작성되었습니다.</p> </blockquote>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Dimensionality Reduction - PCA (Principal Component Analysis)</title><link href="https://tomtom1103.github.io/blog/2022/pca/" rel="alternate" type="text/html" title="Dimensionality Reduction - PCA (Principal Component Analysis)"/><published>2022-07-08T00:00:00+00:00</published><updated>2022-07-08T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/pca</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/pca/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>Introduction</li> <li>Mathematical Background <ul> <li>Covariance Matrix</li> <li>Projection</li> <li>Eigenvalue and Eigenvector</li> </ul> </li> <li>Principal Component Analysis: PCA <ul> <li>Step 1: Data Centering</li> <li>Step 2: Optimization</li> <li>Step 3: Lagrangian Multiplier</li> <li>Step 4: Find Bases</li> <li>Step 5: Select Bases</li> </ul> </li> </ul> <h2 id="introduction">Introduction</h2> <p>이전 장에선 차원축소를 위해 중요한 변수들을 선택하는 방법론들인 FS, BE, SS, 그리고 Genetic Algorithm 에 대해 알아보았다. 이번 장에서 다루는 PCA (주성분분석) 는 기존의 변수들의 특징들을 추출하여 새로운 변수들을 만드는 변수 추출법 (Feature Extraction) 이다. PCA 는 선형변환 feature extraction 중 하나이며, 데이터의 속성을 보존하면서 새로운 변수를 생성한다. 선형변환 feature extraction 방법론들은 기존 데이터의 어떠한 특징을 최대한 보존할지에 따라 나뉘는데, <strong>PCA 는 기존 데이터의 분산을 최대한 보존하는 기저벡터를 찾아 데이터를 사영시키는 방법론이다.</strong></p> <blockquote> <p>Dimensionality Reduction 의 간단한 Taxonomy 는 다음과 같다:</p> <ul> <li><strong>Feature Selection</strong> <ul> <li>Filter <ul> <li>Information Gain</li> <li>Odds Ratio, etc</li> </ul> </li> <li>Wrapper <ul> <li>Forward Selection</li> <li>Backwards Elimination</li> <li>Stepwise Selection</li> <li>Genetic Algorithm</li> </ul> </li> </ul> </li> <li><strong>Feature Extraction</strong> <ul> <li>Max. Variance <ul> <li>PCA (Principal Component Analysis)</li> </ul> </li> <li>Max. Distance Info <ul> <li>MDS (Multidimensional Scaling)</li> </ul> </li> <li>Reveal non-linear structure <ul> <li>LLE</li> <li>ISOMAP</li> <li>t-SNE</li> </ul> </li> </ul> </li> </ul> </blockquote> <h2 id="mathematical-background">Mathematical Background</h2> <p>주성분분석을 알아보기 전 선형대수에서 처음 접하게 된 수리적 배경부터 알아보자. 앞으로 나올 행렬연산의 행은 변수고, 열은 데이터의 샘플로 작성하였다.</p> <h3 id="covariance-matrix">Covariance Matrix</h3> <p>공분산 행렬은 특정 행렬을 통해 계산할 수 있으며, 해당 행렬의 데이터 구조와 특징쌍에 대한 변동에 대한 중요한 정보를 나타낸다. <strong>행렬의 분산의 정보가 담겨있다</strong> 라고 이해할 수 있다.</p> \[Cov(\mathbf{X}) = {1\over n}(\mathbf{X}- \bar{\mathbf{X}})(\mathbf{X}- \bar{\mathbf{X}})^T\\ Cov(\mathbf{X}_{ij}) = Cov(\mathbf{X}_{ji})\] <p>행렬 \(\mathbf{X}\) 에 대한 공분산 행렬은 위와 같이 계산할 수 있다. 이때 \(\mathbf{X}\) 는 \(d \times n\) 의 행렬이기에 공분산 행렬은 \(d \times d\) 의 dimension 을 갖는다. 공분산 행렬은 대칭행렬이고, 전체 데이터셋의 분산은 공분산 행렬의 trace 라는 특징을 갖는다.</p> <h3 id="projection">Projection</h3> <p>선형대수에서 배우는 사영은 주성분분석에서 굉장히 중요한 역할을 한다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/pca/img3-480.webp 480w,/assets/img/posts/machinelearning/pca/img3-800.webp 800w,/assets/img/posts/machinelearning/pca/img3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/pca/img3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>\(\vec b\) 와 \(\vec a\) 가 있을 시, \(\vec b\) 의 끝에서 \(\vec a\) 와 직교하는 수선의 발을 내리고 \(\vec a\) 에 대한 해당 수선의 발 까지의 길이를 \(p\) 라고 하자. 그렇다면 \((\vec b - p \vec a)^T\vec a = 0\) 이 될거고, 이를 전개 후 \(p\) 에 대해 정리하면 \(p = {\vec b^T\vec a \over \vec a^T \vec a }\) 가 된다. \(p\vec a = \vec x\) 라고 정의한다면 \(\vec x = p \vec a = {\vec b^T\vec a \over \vec a^T \vec a } \vec a\) 가 된다. <strong>이때 \(\vec a\) 가 기저벡터라면</strong> \(p = \vec b^T\vec a\) 가 되며, \(\vec x = p \vec a = (\vec b^T \vec a)\vec a\) 가 된다.</p> <p><strong>이때 \(p\) 는 원래 벡터 \(\vec b\) 를 기저벡터 \(\vec a\) 에 사영시킨 후의 scalar 값이 된다.</strong></p> <h3 id="eigenvalue-and-eigenvector">Eigenvalue and Eigenvector</h3> <p>고윳값과 고유벡터는 주성분분석의 핵심역할을 담당한다.</p> \[\mathbf{Ax=\lambda x} \rightarrow \mathbf{(A-\lambda I)x}=0\] <p>\(\mathbf{x}\) 라는 벡터에 \(\mathbf{A}\) 라는 선형변환을 취했다. 이때 선형변환 후의 행렬이 scalar 값인 \(\lambda\) 와 기존 \(\mathbf{x}\) 의 곱으로 표현할 수 있다면, \(\lambda\) 는 행렬 \(\mathbf{A}\) 의 고윳값이며 \(\mathbf{x}\) 는 행렬 행렬 \(\mathbf{A}\) 의 고유벡터이다.</p> <p>만약 행렬 \(\mathbf{A}\) 의 역행렬이 존재한다면 (non-singular matrix 이라면), rank \(d\) 개의 고윳값-고유벡터 쌍이 존재한다. 그리고 이 행렬의 trace 는 고윳값의 합과 같다.</p> <p>앞서 언급했듯이 전체 데이터셋의 분산은 데이터셋의 공분산 행렬의 trace 와 같다. 해당 공분산 행렬의 역행렬이 존재한다면, 행렬의 trace 는 고윳값의 합이다. <strong>즉, 특정 데이터셋의 전체 분산은 공분산 행렬의 고윳값의 합이다.</strong></p> <blockquote> <p>추가적인 설명이 필요하다면 <a href="https://angeloyeo.github.io/2019/07/27/PCA.html">공돌이의 수학정리노트</a> 를 참고하자. 명쾌하고 직관적인 설명을 해주신다.</p> </blockquote> <h2 id="principal-component-analysis-pca">Principal Component Analysis: PCA</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/pca/img1-480.webp 480w,/assets/img/posts/machinelearning/pca/img1-800.webp 800w,/assets/img/posts/machinelearning/pca/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/pca/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>위 예시는 3차원의 데이터를 2차원으로 사영시킨 PCA 의 시각적 예시다. 기존의 데이터는 3차원의 feature space 에 분포가 되어있는데, 데이터의 분산을 최대한 보존시키며 사영을 하니 3차원에서 볼 수 있었던 데이터의 군집이 그대로 2차원에도 표현이 된 것이다.</p> <blockquote> <p>Purpose: Find a set of orthogonal basis vectors that can preserve the variance of the original data as much as possible after projecting it upon the set.</p> </blockquote> <p>\(X_1, X_2, ...,X_p:\) Original Variables</p> <p>\(\mathbf{a}_i = [a_{i1},a_{i2},...,a_{ip}]:\) \(i^{th}\) Basis vector/Principal Component</p> <p>\(Y_1, Y_2,...,Y_p:\) Variables after the projection onto the \(i^{th}\) Basis Vector</p> <p>기존 데이터셋에 p개의 변수가 있고, p 개의 변수벡터들을 각각 기저벡터 \(\mathbf{a}_i\) 에 사영하면 scalar 값인 \(Y_i\) 가 나온다. 이때 \(Y_i\) 의 분산을 계산하고, 분산이 최댓값이 되는 기저벡터 \(\mathbf{a_i}\), 즉 <strong>주성분</strong>을 를 찾는것이 PCA 의 주 목적이다. 이때 몇개의 주성분을 사용할지는 분석가의 선택이다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/pca/img2-480.webp 480w,/assets/img/posts/machinelearning/pca/img2-800.webp 800w,/assets/img/posts/machinelearning/pca/img2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/pca/img2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>분산이 보존된다는 것은 위 그림을 보면 직관적으로 이해가 가능하다. 데이터셋을 두개의 주성분에 사영시켰을 시, 보존되는 분산의 정도는 \(\lambda_i\) 로 계산할 수 있다.</p> <h3 id="step-1-data-centering">Step 1: Data Centering</h3> <p>예시를 통해 주성분분석의 작동방식을 살펴보자. 이때 데이터셋은 기존에 사용하는 행렬과 반대로 \(d \times n\) 차원의 행렬로 표현한다 (행에 변수, 열에 샘플).</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/pca/img4-480.webp 480w,/assets/img/posts/machinelearning/pca/img4-800.webp 800w,/assets/img/posts/machinelearning/pca/img4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/pca/img4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>먼저 Data Centering 을 통해 객체들을 평균값으로부터 빼준다 (Normalizing).</p> <blockquote> <p>사실 Data Centering 단계에 대한 의문이 들었다. 어짜피 공분산 행렬 \(Cov(\mathbf{X}) = {1\over n}(\mathbf{X}- \bar{\mathbf{X}})(\mathbf{X}- \bar{\mathbf{X}})^T\) 는 데이터의 분산의 정보를 나타내기 때문에 Centering 을 하던말던 공분산 행렬은 변하지 않기 때문이다.</p> <p><a href="https://stats.stackexchange.com/questions/189822/how-does-centering-make-a-difference-in-pca-for-svd-and-eigen-decomposition">How does centering make a difference in PCA (for SVD and eigen decomposition)?</a> 는 같은 의문을 던지는데, 정리하자면 ‘Non Centered Data’ 를 통한 주성분분성이라 함은 공분산 행렬 대신 \(\mathbf{X^T X}/(n-1)\) 행렬로 고윳값분해를 진행하는 방법론이다.</p> </blockquote> <h3 id="step-2-optimization">Step 2: Optimization</h3> <p>기존 데이터셋은 \(p\) 개의 변수가 있다. 분산이 최대화 되는 기저벡터 \(w\) 에 변수벡터 \(x\) 를 사영시켜야 하는데, 사영 후의 분산은 다음과 같이 계산 할 수 있다.</p> \[V = {1 \over n}(\mathbf{w^T X})(\mathbf{w^T X})^T = {1 \over n}(\mathbf{w^T XX^T w}) = \mathbf{w^T Sw}\] <p>기저벡터 \(\mathbf{w}\) 과 전체 데이터셋 \(\mathbf{X}\) 에 대한 scalar 분산 값은 \(V\) 다. 첫번째 항을 잘 보면 공분산 행렬을 구하는 공식과 닮아있다. 이를 전개하고 공분산 행렬의 식이 \({1\over n}\mathbf{XX^T}\) (Normalize 하였다는 전제하에) 인 것을 기억하자. 이를 sample 공분산 행렬 \(\mathbf{S}\) 라고 치환하면 분산을 마지막 항인 \(\mathbf{w^T Sw}\) 로 표현 할 수 있다.</p> <p>주성분분석은 사영 후의 분산값의 최대화 이기 때문에, 다음과 같은 모델링으로 표현 할 수 있다.</p> \[\mathbf{max \ w^T Sw}\\ \mathbf{s.t. \ w^T w}=1\] <h3 id="step-3-lagrangian-multiplier">Step 3: Lagrangian Multiplier</h3> <p>위의 최적화 문제는 제약식에 strict equality 가 존재하므로, 라그랑주 승수법을 사용한다.</p> \[\mathcal{L} = \mathbf{w^T Sw - \lambda (w^T w-1)}\\ {\partial \mathcal{L} \over \partial \mathbf{w}} = 0 \Rightarrow \mathbf{Sw - \lambda w} = 0 \Rightarrow (\mathbf{S-\lambda I})\mathbf{w} = 0\] <p>즉, 기저벡터 \(\mathbf{w}\) 에 대한 1차도함수가 0이 되는 지점으로 편미분을 진행한다면 해는 위에서 구한 sample 공분산 행렬의 고윳값과 고유벡터로 표현 할 수 있다. <strong>구하고자 하는 기저벡터가 sample 공분산 행렬의 고유벡터가 되는 것이다.</strong></p> <h3 id="step-4-find-bases">Step 4: Find Bases</h3> <p>첫 단계에서 두개의 변수를 가진 데이터셋을 다시 예시로 들자면, 두개의 고유벡터-고윳값 쌍이 구해진다. 이때 고윳값을 내림차순으로 정리한 뒤 해당 고유벡터를 기저로 사용하면 된다.</p> <p>데이터를 첫번째 기저벡터에 사영한다면, 분산은 다음과 같이 계산할 수 있다.</p> \[V = {1 \over n}(\mathbf{w_1^T X})(\mathbf{w_1^T X})^T = {1 \over n}(\mathbf{w_1^T XX^T w_1}) = \mathbf{w_1^T Sw_1}\\ \text{since} \ \mathbf{Sw_1} = \lambda_1 \mathbf{w_1}, \ \mathbf{w_1^T Sw_1} = \mathbf{w_1^T \lambda_1 w_1} = \lambda_1 \mathbf{w_1^T w_1} = \lambda_1\] <p><strong>즉, 데이터를 고유벡터인 기저벡터 \(\mathbf{w_1}\) 에 사영한다면 데이터의 분산은 고윳값인 \(\lambda_1\) 이 된 다.</strong></p> <h3 id="step-5-select-bases">Step 5: Select Bases</h3> <p>기저벡터들과 보존되는 분산의 양을 찾았다면 몇개의 기저벡터들을 사용할지 정해야 한다. 이때 closed form solution 은 존재하지 않으므로 데이터의 분산을 얼만큼 보존하고 싶은지에 따라 cutoff 를 정할 수 있다.</p> <p>데이터셋에 대한 분산은 고윳값의 총합이기 때문에, 하나의 기저에 데이터를 사영 시 보존되는 분산의 양은 다음과 같이 계산할 수 있다.</p> \[{\lambda_k \over \lambda_1 + \lambda_2 + ... + \lambda_d}\] <p>보통 사용하는 주성분의 개수가 늘어날수록 보존되는 분산의 양이 급격히 감소한다. 이에 따라 Scree Plot 을 도식하여 elbow point 에 따라 cutoff 를 정할 수 있고, 전체 데이터에 대한 cutoff 를 정하고 싶다면 Cumulative variance plot 을 그려 cutoff 를 정한다.</p> <blockquote> <p>데이터셋이 가우스 분포를 따르고 있지 않다면 주성분분석의 성능이 급격히 낮아진다는 치명적인 단점이 있다. 통계에서 출범된 방법론이기 때문에 현실 데이터셋에 실용적인 적용을 못 할 수 있지만, 이에 따라 FLDA 같은 방법론이 발전하였다.</p> </blockquote> <p><strong>정리:</strong></p> <p>PCA 의 목적은 데이터가 가지고 있는 특징을 분산으로 정의하여, 원 데이터의 분산을 제일 잘 보존하는 소수의 기저 (주성분)을 찾아 원 데이터를 이에 사영시켜 차원축소를 하는 방법론이다.</p> <blockquote> <p>해당 포스트는 강필성 교수님의 <a href="https://github.com/pilsung-kang/Business-Analytics-IME654-">Business Analytics</a> 를 참고하여 작성되었습니다.</p> </blockquote>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Ensemble Learning - Gradient Boosting Machine</title><link href="https://tomtom1103.github.io/blog/2022/gbm/" rel="alternate" type="text/html" title="Ensemble Learning - Gradient Boosting Machine"/><published>2022-07-07T00:00:00+00:00</published><updated>2022-07-07T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/gbm</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/gbm/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>Gradient Boosting Machine: GBM</li> <li>The Gradient</li> <li>Regularization of GBM <ul> <li>Subsampling</li> <li>Shrinkage</li> <li>Early Stopping</li> </ul> </li> <li>Variable Importance in Tree-based GBM</li> </ul> <blockquote> <p>해당 포스트는 2021년 1학기 고려대학교 강필성 교수님의 ‘<a href="https://github.com/pilsung-kang/multivariate-data-analysis">다변량분석</a>’ 강의를 참고하여 작성되었습니다.</p> <p>이미지는 강필성 교수님의 강의 슬라이드에서 발췌하였습니다.</p> <p><del>A+ 감사했습니다 교수님</del></p> </blockquote> <h2 id="gradient-boosting-machine-gbm">Gradient Boosting Machine: GBM</h2> <p>앙상블 기법은 크게 병렬처리가 가능한 bagging, 그리고 불가능한 boosting 방법론들로 나뉜다. Gradient Boosting Machine (GBM) 은 이름에서 알 수 있듯이 Boosting 방법론 중 하나이며, weak model 을 guide 로 학습을 진행한다. Boosting 방법론들 중 shortcomings 라는 단어가 쓰이는데, 이는 Boosting 모델이 이전 단계에서 효과적으로 학습을 진행하지 못했기에 가중치로 삼을 객체를 의미한다. 예시로, AdaBoost 의 shortcomings 는 분류를 잘 못한 샘플 \(i\) 에 대한 가중합이다. GBM 은 shortcomings 를 이름에서 알 수 있듯이 gradient, 즉 경사를 사용한다.</p> <blockquote> <p>GBM 은 머신러닝의 대표적인 3가지 task 인 regression, classificaiton, ranking 에 전부 적용 할 수 있다. 하지만 Gradient, 즉 손실함수에 대한 1차도함수를 계산하는 과정이 있기 때문에 base model 의 손실함수를 미분할 때의 computational complexity 에 따라 difficulty 를 매기기도 한다. 일반적으론 Regression &lt; Classification &lt; Ranking 의 Difficulty 를 가진다.</p> </blockquote> <p>GBM 의 기본 개념은 (Regression 모델을 예시로 두었을 때) 잔차에서 비롯된다. 먼저 설명변수와 종속변수를 잘 설명하는 회귀식을 구축 한 다음, 각 샘플에 대한 잔차를 계산한다. Boosting 방법론이기 때문에 그 다음 모델을 학습하는데, 이때 다음 모델의 종속변수로 이전 단계의 모델의 잔차를 사용한다. <strong>즉, 다음 단계의 모델은 이전 단계의 모델의 에러를 예측하는 모델을 구축하는 것이다.</strong></p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/gbm/img1-480.webp 480w,/assets/img/posts/machinelearning/gbm/img1-800.webp 800w,/assets/img/posts/machinelearning/gbm/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/gbm/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <h2 id="the-gradient">The Gradient</h2> <p>GBM 에서의 Gradient 라는 워딩은 경사하강법과 연결된다. 예시로, 다중선형회귀분석의 손실함수로 OLS 를 사용한다.</p> \[\textbf{min}\ L = {1 \over 2} \sum ^n_{i=1} (y_i - f(\mathbf{x}_i))^2\] <p>이때 \(\mathbf{x_i}\) 에 대한 손실함수의 1차도함수는 다음과 같다.</p> \[{\partial L \over \partial f(\mathbf{x}_i)} = f(\mathbf{x}_i) - y_i\] <p>이를 잔차에 대해 정리를 하면 다음과 같다.</p> \[y_i - f(\mathbf{x}_i) = - {\partial L \over \partial f(\mathbf{x}_i)}\] <p><strong>즉, 잔차를 손실함수의 negative gradient 로 표현 할 수 있다.</strong> 그렇기에 GBM 의 모델들을 학습시킬 때 종속변수를 각 샘플에 대한 이전 단계의 모델의 negative gradient 로 설정하는 것이 잔차로 설정하는 것과 동일한 효과를 낸다. 결국 GBM 은 매 iteration 마다 전 단계의 gradient 만큼만 학습시키는 것이다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/gbm/img2-480.webp 480w,/assets/img/posts/machinelearning/gbm/img2-800.webp 800w,/assets/img/posts/machinelearning/gbm/img2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/gbm/img2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>위 예시는 base learner 을 regression stump tree 로 사용한 GBM 모델이다. Regression stump tree 는 split 을 기준으로 해당 영역의 샘플들의 평균으로 예측을 해주는 모델이다. 첫째 모델은 하나의 split 을 보이며, 이에 따른 잔차들을 기준으로 두번째 모델을 학습시킨다. Iteration 을 거듭할 수록 값들을 잘 예측하는 것을 볼 수 있으며, 최종 모델의 잔차들은 거의 0에 수렴하는 것을 볼 수 있다.</p> <h2 id="regularization-of-gbm">Regularization of GBM</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/gbm/img3-480.webp 480w,/assets/img/posts/machinelearning/gbm/img3-800.webp 800w,/assets/img/posts/machinelearning/gbm/img3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/gbm/img3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>GBM 의 알고리즘은 위와 같다. AdaBoost 와는 달리, 마지막에 학습된 모든 모델을 aggregate 하지 않고 마지막 iteration \(M\) 에서 구한 모델을 최종 모델로 사용한다. GBM 은 사용하는 손실함수에 따라 알고리즘의 차이가 날 수 있다.</p> <p>Regression 을 위한 GBM 에서는 대표적으로 \(L_1\) Loss, \(L_2\) Loss, Huber Loss, Quantile Loss 를 사용하며,</p> <p>Classification 을 위한 GBM 에서는 대표적으로 Bernoulli Loss, AdaBoost Loss 를 사용한다. 이때 주어진 task 가 Binary classification 이면 AdaBoost 와 동일하게 초기 정답라벨을 \(y \in \{-1,1\}\) 로 사용한다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/gbm/img4-480.webp 480w,/assets/img/posts/machinelearning/gbm/img4-800.webp 800w,/assets/img/posts/machinelearning/gbm/img4-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/gbm/img4.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>GBM 은 이전 단계 모델의 잔차를 이용한 학습을 한다는 특징이 있기 때문에, 과적합의 고질적인 문제가 있다. 실제 모델엔 어쩔 수 없는 noise 인 \(\epsilon\) 이 포함되있길 마련인데, 잔차에 이런 noise 가 포함되어있을 확률이 높기 때문이다. 그렇기에 GBM 에선 여러가지 정규화 방법론이 쓰인다.</p> <h3 id="1-subsampling">1. Subsampling</h3> <p>첫번째 정규화 방법론은 subsampling 이다. AdaBoost 에선 각 샘플이 뽑힐 확률을 높혀주는 가중치를 통한 복원추출로 데이터셋을 만들지만, 기본적인 GBM 모델은 모든 샘플을 그대로 사용한다. 하지만 모든 샘플을 사용하면 과적합의 위험이 있기에, 각 iteration 마다 데이터셋의 subset 만 사용하는 것이 subsampling 이다. <strong>이때 GBM 에서 사용되는 subsampling 의 특징은 AdaBoost, Bagging 과는 다른 비복원추출이라는 점이다.</strong></p> <blockquote> <p>만약 샘플률을 80%라고 가정하면 매 iteration 마다 샘플의 수가 줄어드는 것이라고 생각할 수 있지만, 아니다.</p> <p>10개의 샘플을 가진 기존 데이터셋에서 두번째 데이터셋을 만들 때 8개가 랜덤추출되며, 8개의 샘플에 대한 잔차가 두번째 모델을 학습시키기 위한 정답라벨이 된다. 이후 세번째 데이터셋은 기존 데이터셋에서의 80% 인 8개를 추출하며, 이 8개의 샘플에 대해 첫번째 모델과 두번째 모델을 합친 모델에서의 잔차를 계산하여 세번째 모델의 학습에 사용된다.</p> </blockquote> <h3 id="2-shrinkage">2. Shrinkage</h3> <p>이전에 살펴본 Shrinkage methods 와 동일한 맥락으로, 특정 객체의 impact 를 줄여주는 가중치를 추가하는 방법론이다. 기본 GBM 에선 매 iteration 마다 만들어지는 모델의 가중치가 동일하다면, Shrinkage method 를 사용한 GBM 은 factor \(\lambda\) 를 추가하여 나중에 만들어지는 모델의 영향력을 감소시킨다.</p> <h3 id="3-early-stopping">3. Early Stopping</h3> <p>다른 인공신경망 모델들에서 사용되는 동일한 방법론으로, Validation Error 을 통해 급격히 증가할것같은 구간에서 알고리즘을 미리 종료하는 방법론이다.</p> <h2 id="variable-importance-in-tree-based-gbm">Variable Importance in Tree-based GBM</h2> <p>Kaggle 에서 진행되는 대회들을 보면, 상위권엔 항상 앙상블 방법론들이 있다. 이중 Random Forest 와 GBM 이 압도적으로 쌍벽을 이루는 경우가 많은데, 이 두 알고리즘은 모델의 성능을 향상시켜줄 뿐만 아니라 변수의 중요도 또한 산출하기 때문이다. RF 와 동일하게 base learner 를 Decision tree (혹은 stump tree) 를 사용 할 시, Influence 를 계산하여 최종 모델을 구축하는데 있어 각 변수의 중요도를 계산할 수 있다.</p> \[Influence_j(T) = \sum^{L-1}_{i=1}(IG_i \times \mathbf{1}(S_i=j))\] <p>\(Influence_j(T)\) 는 단일 tree \(T\) 에서 사용된 변수 \(j\) 에 대한 중요도의 계산식이다.</p> <p>해당 tree \(T\) 에 \(L\) 개의 leaf node 가 있으면, split 의 개수는 \(L-1\) 이다.</p> <p>\(IG_i\) 는 Information gain, 즉 혼잡도의 감소를 나타내며 \(\mathbf{1}(S_i=j)\) 는 단순히 해당 split \(i\) 에서 변수 \(j\) 를 사용했다면 1을 반환해주는 함수다.</p> <p><strong>즉, 단일 tree 에 대한 변수 \(j\) 의 중요도는 해당 tree 에서 해당 변수가 사용되었을 때 Information Gain 의 합이다.</strong></p> \[Influence_j = {1\over M}\sum^M_{k=1}Influence_j(T_k)\] <p>전체 GBM 모델에 대한 변수 \(j\) 의 중요도는 위 식으로 구할 수 있다. 단순히 모든 Tree 에 대한 \(j\) 의 중요도의 평균이다.</p>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Contents]]></summary></entry><entry><title type="html">Ensemble Learning - Adaptive Boosting</title><link href="https://tomtom1103.github.io/blog/2022/adaboost/" rel="alternate" type="text/html" title="Ensemble Learning - Adaptive Boosting"/><published>2022-07-06T00:00:00+00:00</published><updated>2022-07-06T00:00:00+00:00</updated><id>https://tomtom1103.github.io/blog/2022/adaboost</id><content type="html" xml:base="https://tomtom1103.github.io/blog/2022/adaboost/"><![CDATA[<h2 id="contents">Contents</h2> <ul> <li>Adaptive Boosting</li> <li>AdaBoost: Algorithm</li> </ul> <blockquote> <p>해당 포스트는 2021년 1학기 고려대학교 강필성 교수님의 ‘<a href="https://github.com/pilsung-kang/multivariate-data-analysis">다변량분석</a>’ 강의를 참고하여 작성되었습니다.</p> <p>이미지는 강필성 교수님의 강의 슬라이드에서 발췌하였습니다.</p> <p><del>A+ 감사했습니다 교수님</del></p> </blockquote> <h2 id="adaptive-boosting">Adaptive Boosting</h2> <p>이전 장에서 살펴본 Bagging 은 bootstrap 을 만들어 high model complexity 를 가진 모델을 학습시킨 뒤, 적절히 결합하는 앙상블 방법론이다. Boosting 은 반대로 하나의 데이터셋에 하나의 모델을 학습시킨 후, 풀어내지 못한 것에 대해 다음단계에서 중점적으로 학습을 반복하는 방법론이다.</p> <p>Boosting 에선 Strong vs. Weak model 이란 개념이 등장한다. Classifier 기준으로, Weak model 은 random guessing 보다 성능이 아주 약간 좋은 모델을 의미하며, boosting 은 이런 Weak model 을 기준으로 Strong model 을 향해 나아간다. Boosting 은 데이터셋을 통해 성능이 아주 낮은 weak model 을 먼저 학습시킨 뒤, 오분류한 데이터셋 속 샘플에 대해 가중치를 부여하고 새로운 모델의 학습을 반복한다. 이렇기 때문에 bagging 과는 달리 병렬연산이 불가능하다.</p> <blockquote> <p>Bagging 은 병렬처리가 가능하고, Boosting 은 병렬처리가 불가능하지만 실제로는 Boosting 의 학습이 훨씬 빠른 경우를 종종 볼 수 있다. Bagging 은 애초에 High complexity 를 가진 모델을 병렬 연산하는 것이고, Boosting 은 Weak model 을 직렬연산하는 것이다. 하지만 오히려 Weak model 의 직렬연산이 Bagging 의 high complexity 모델 하나를 학습시키는것보다 빠른 경우가 많다.</p> </blockquote> <p>Adaptive boosting 은 Boosting 방법론 중 weak model 을 stump tree 로 사용하는 앙상블 방법론이다. Stump tree 란 decision boundary split 을 단 1번만 진행한 Decision tree 를 의미하며, (제대로 학습이 이루어졌다고 가정하면) random guessing 보다 성능이 약간 좋다는 특징을 가진다.</p> <h2 id="adaboost-algorithm">AdaBoost: Algorithm</h2> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/adaboost/img1-480.webp 480w,/assets/img/posts/machinelearning/adaboost/img1-800.webp 800w,/assets/img/posts/machinelearning/adaboost/img1-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/adaboost/img1.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <ol> <li> <p>AdaBoost 의 지정 hyperparameter \(T\) 는 individual learner 의 개수를 의미한다. AdaBoost 는 직렬연산을 기반한 알고리즘이기 때문에, individual learner 의 개수는 곧 알고리즘의 iteration 을 의미한다. 보통 50~100개를 지정한다.</p> </li> <li> <p>AdaBoost 의 Input 은 \(N\) 개의 정답 pair 을 가진 학습 데이터셋 \(S\) 다. 이때 주목할만한 점은 정답라벨 \(y_i\) 다. 일반적인 Classification 을 수행하기 위해 데이터셋의 정답라벨은 \(0,1\) 의 값을 갖는데 AdaBoost 의 특성상 \(-1, 1\) 을 사용한다. 예측하는데 있어 아무런 차이가 없지만, 이렇게 값을 바꾸어 사용하는 이유는 weight update 에서 확인 할 수 있다.</p> </li> <li> <p>\(D_1(i)\) 는 1번째 iteration 에서 sample \(i\) 가 선택될 확률분포를 의미한다. <strong>알고리즘 초기엔 일양분포를 사용함으로써 \(i\) 가 선택될 확률은 다른 sample 들과 동일하지만, iteration 이 진행되며 이 분포는 바뀐다.</strong></p> </li> <li> <p>for loop 을 이용해서 individual learner 의 개수만큼 알고리즘을 반복한다.</p> <ol> <li> <p>확률분포 \(D_t\) 를 이용하여 모델 \(h_t\) 를 학습시킨다. 여기서 주목할 점은 AdaBoost 의 학습용 데이터셋 생성은 Boosting 과 마찬가지로 복원추출을 사용하지만, 첫번째 iteration 에서만 복원추출하는 방식이 Uniform distribution 이기 때문에 random 하다. 이때 \(h_t\) 는 Stump tree 를 의미한다.</p> </li> <li> <p>오분류율인 \(\epsilon_t = P_{D_t}(h_t(x)\neq y)\) 을 계산한다.</p> </li> <li> <p>오분류율 \(\epsilon_t \geq 0.5\) 면 알고리즘을 종료하고 다시 처음부터 시작한다. 학습한 모델은 weak model 인 stump tree 이기 때문에, 아무리 성능이 낮을지언정 random guessing 보다 성능이 좋아야 한다. 오분류율이 0.5 보다 크거나 같다는 의미는 stump tree 가 random guessing 보다 못했다는 것을 의미하기 때문에, 처음부터 다시 해보라는 일종의 장치를 걸어둔 것이다.</p> </li> <li>\(\alpha_t = {1\over2}ln({1-\epsilon_t \over \epsilon_t})\) 를 계산하여 가중치 \(\alpha_t\) 를 구한다.</li> <li>\(D_{t+1}(i)= {D_t(i)\mathbf{exp}(-\alpha_t y_i h_t (x_i))\over Z_t}\) 를 통해 다음 iteration 의 샘플들이 선택되는 확률분포를 update 한다. <strong>이 부분을 통해 다음 iteration 에서 샘플들이 복원추출로 선택되는 확률이 달라지는 것이다.</strong> \(Z_t\) 는 정규화 factor 이다.</li> </ol> </li> <li> <p>\(T\) 만큼의 iteration 이 종료되면, 모든 모델 \(h_t\) 와 이에 대한 \(\alpha_t\) 값을 더한 뒤, testing sample \((x',y')\) 를 넣어 모델을 검증한다.</p> </li> </ol> \[D_{t+1}(i)= {D_t(i)\mathbf{exp}(-\alpha_t y_i h_t (x_i))\over Z_t}\] <p>AdaBoost 의 핵심은 \(D_t\) 의 계산에서 볼 수 있다.</p> <p>먼저, \(D_t(i)\) 는 \(t\) 시점에서 샘플 \(i\) 가 선택될 확률을 의미한다.</p> <p>\(\alpha_t\) 의 계산식 \({1\over2}ln({1-\epsilon_t \over \epsilon_t})\) 를 보면 오분류율에 따라 계산이 되기 때문에, 모델의 정확도가 높을수록 \(\alpha_t\) 가 크다.</p> <p>데이터셋의 정답라벨을 왜 \(y_i \in \{-1,1\}\) 으로 설정해야하는지는 \(y_i h_t (x_i)\) 의 작동 원리때문이다. \(y_i\) 는 샘플 \(i\)의 정답라벨이고, \(h_t(x_i)\) 는 stump tree 의 예측값이다. 만약 샘플 \(i\) 에 대해 모델이 올바르게 예측했다면 \(y_i h_t (x_i)\) 는 1이 될것이고, 올바르게 예측을 못했다면 \(y_i h_t (x_i)\) 는 -1 이 될것이다.</p> <p>그렇기에 \(\mathbf{exp}(-\alpha_t y_i h_t (x_i))\) 는 <strong>\(h_t\) 가 성능이 높고 샘플 \(i\) 를 올바르게 예측했다면 \(i\) 가 선택될 확률을 줄이는 것이고, \(h_t\) 가 정확한 모델임에도 불구하고 \(i\) 를 올바르게 예측을 못했다면 \(i\) 가 선택될 확률을 다음 단계에서 높히는 것을 의미한다.</strong> 이때 \(i\) 가 선택될 확률, 즉 증가/감소 폭은 모델의 성능인 가중치 \(\alpha_t\) 에 의해 결정된다.</p> <p>AdaBoost 는 위와 같은 알고리즘으로 이전단계에 분류를 잘 못한 샘플에 대해 복원추출에서 선택될 확률을 높힘으로써, 모델의 성능을 확보한다.</p> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/adaboost/img2-480.webp 480w,/assets/img/posts/machinelearning/adaboost/img2-800.webp 800w,/assets/img/posts/machinelearning/adaboost/img2-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/adaboost/img2.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <div class="row mt-3"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/machinelearning/adaboost/img3-480.webp 480w,/assets/img/posts/machinelearning/adaboost/img3-800.webp 800w,/assets/img/posts/machinelearning/adaboost/img3-1400.webp 1400w," sizes="95vw" type="image/webp"/> <img src="/assets/img/posts/machinelearning/adaboost/img3.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </div> </div> <p>위 그림을 보면 Bagging 에서 각 Bootstrap 마다 선택되는 샘플들과 Boosting 의 iteration 마다 선택되는 샘플들을 비교할 수 있다. Bagging 에선 모든 샘플들이 random 하게 복원추출이 되는 반면, Boosting 에선 4번째 iteration 을 위해 추출된 데이터에선 1이 이전 단계보다 훨씬 많이 등장하는 것을 볼 수 있다.</p>]]></content><author><name></name></author><category term="machine-learning"/><summary type="html"><![CDATA[Contents]]></summary></entry></feed>